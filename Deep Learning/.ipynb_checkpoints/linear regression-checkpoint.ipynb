{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlis = []\n",
    "ylis = []\n",
    "flis = [] \n",
    "wlis = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=10\n",
    "size=1\n",
    "weights={}\n",
    "#data_set={}    \n",
    "loss_grad={}    # dJdW, dJdB 저장공간\n",
    "forward_info={} # 순방향 저장공간\n",
    "batch={}\n",
    "\n",
    "W= np.random.uniform(-R,R,size=size)\n",
    "b= np.random.uniform(-R,R,size=1)\n",
    "\n",
    "for i in range(1000):\n",
    "    x = np.random.uniform(-R,R,size=size)\n",
    "    y = np.random.normal(W*x+b,1,size=size)\n",
    "    xlis.append(x)\n",
    "    ylis.append(y)\n",
    "    flis.append(W*x+b)\n",
    "\n",
    "x=np.array(xlis)\n",
    "y=np.array(ylis)\n",
    "\n",
    "weights['W']=W\n",
    "weights['B']=b\n",
    "\n",
    "result=np.concatenate((x,y),axis=1)\n",
    "\n",
    "train_idx=int(result.shape[0]*0.85)\n",
    "dev_idx=int(result.shape[0]*0.05)\n",
    "test_idx=int(result.shape[0]*0.1)\n",
    "\n",
    "train_data_set=result[0:train_idx,:]\n",
    "test_data_set=result[train_idx:train_idx+test_idx,:]\n",
    "dev_data_set=result[train_idx+test_idx:train_idx+test_idx+dev_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x24453a89b48>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(xlis,ylis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.45088265]\n",
      "[0.30304375]\n"
     ]
    }
   ],
   "source": [
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(850, 2)\n",
      "(850,)\n",
      "(850, 1)\n"
     ]
    }
   ],
   "source": [
    "data=train_data_set\n",
    "idx=train_idx\n",
    "minibatch_size=1\n",
    "data=np.random.permutation(data)\n",
    "\n",
    "#epoch\n",
    "print(data.shape)\n",
    "X_batch= data[:,0]\n",
    "print(X_batch.shape)\n",
    "y_batch= data[:,1]\n",
    "X_batch=np.reshape(X_batch,(idx,size))\n",
    "y_batch=np.reshape(y_batch,(idx,size))\n",
    "\n",
    "print(X_batch.shape)\n",
    "\n",
    "number_minibatch= np.int(np.ceil(X_batch.shape[0]/minibatch_size))\n",
    "\n",
    "#iteration\n",
    "# i=1\n",
    "# X_batch_temp=X_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "# y_temp=y_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.W=np.random.uniform(-R,R,size=size)\n",
    "        self.b=np.random.uniform(-R,R,size=1)\n",
    "        self.N=0\n",
    "        self.f=0\n",
    "        self.loss=0\n",
    "        self.w_grad=np.zeros(size)\n",
    "        self.b_grad=np.zeros(1)\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        self.N = self.W*x\n",
    "        self.f = self.N+self.b\n",
    "        self.loss=np.mean(np.power(y-self.f,2))\n",
    "        \n",
    "#         print('w',self.W.shape)\n",
    "#         print(self.b.shape)\n",
    "#         print(x.shape)\n",
    "#         print(y.shape)\n",
    "#         print(self.N.shape)\n",
    "#         print(self.f.shape)\n",
    "#         print('loss',self.loss.shape)\n",
    "        \n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self,x,y):\n",
    "        batch_size=x.shape[0]\n",
    "        dJdf = 2*(self.f-y)/batch_size\n",
    "        #print(dJdf)\n",
    "        dfdN=np.ones_like(self.N) \n",
    "        #print('dfdN',dfdN)\n",
    "        dfdB=np.ones_like(self.N)\n",
    "        #print(dfdB)\n",
    "        \n",
    "        dJdN=dJdf*dfdN\n",
    "#         print('dJdN',dJdN.shape)\n",
    "        #print(dJdN)\n",
    "        dNdW=np.transpose(x,(1,0))\n",
    "        #print(dNdW)\n",
    "        dJdW=np.dot(dNdW, dJdN)\n",
    "#         print(dJdW.shape)\n",
    "        #print(dJdW)\n",
    "        dJdB=(dJdf*dfdB).sum(axis=0)\n",
    "        #print(dJdB)\n",
    "        self.w_grad=dJdW\n",
    "        self.b_grad=dJdB\n",
    "\n",
    "#         dJdW=2*(self.f-y)/batch_size*x\n",
    "#         dJdb=2*(self.f-y)/batch_size\n",
    "#         self.w_grad=sum(dJdW)\n",
    "#         self.b_grad=sum(dJdb)\n",
    "\n",
    "        self.W=self.W - 0.001 * self.w_grad\n",
    "        self.b=self.b - 0.001 * self.b_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model()\n",
    "# print(model.W)\n",
    "# print(model.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* 1 번차 epoch *************\n",
      "0.0004892759115479702 \t 13.375001751670126\n",
      "3.7932003048908065 \t 10.127096803686623\n",
      "7.120517958921674 \t 8.393168985510124\n",
      "14.812482914196194 \t 7.184110648276089\n",
      "2.267351193447741 \t 6.301492307352047\n",
      "0.06514102127675449 \t 5.673266404400896\n",
      "0.38941899924603246 \t 5.11903358539437\n",
      "2.649766252886864 \t 4.692745221464606\n",
      "************* 2 번차 epoch *************\n",
      "5.165448593569632 \t 1.3666624788843604\n",
      "3.1103042312745615 \t 1.3393848648838889\n",
      "0.001795681007026583 \t 1.2495986718766456\n",
      "0.12775115938430961 \t 1.262502689867242\n",
      "1.7911283645229281 \t 1.245364661137218\n",
      "0.09908667528057707 \t 1.2285680481495287\n",
      "0.11334011521420376 \t 1.2024633906953381\n",
      "0.05752905630536603 \t 1.1896303308430283\n",
      "************* 3 번차 epoch *************\n",
      "0.02765777136771625 \t 1.2099327101990949\n",
      "1.7175791032480139 \t 1.0699130195149718\n",
      "0.3114259777613636 \t 1.0200180230362328\n",
      "0.090265088452497 \t 0.9989735365076572\n",
      "0.1831584471548307 \t 1.0134403110447021\n",
      "0.11058407828739622 \t 1.0605835271824284\n",
      "1.8351583183983307 \t 1.0483629959130567\n",
      "0.8971803890514745 \t 1.053803758510253\n",
      "************* 4 번차 epoch *************\n",
      "0.005855902425213718 \t 1.1904320523450544\n",
      "0.6313304144100189 \t 1.0266297119232393\n",
      "0.028571519353103283 \t 1.058390509530385\n",
      "0.7736990145462134 \t 1.1281077234847359\n",
      "0.9592417769461468 \t 1.0881901039942394\n",
      "0.9666467935121079 \t 1.0625452116990524\n",
      "0.09967980136754176 \t 1.0732820143748836\n",
      "0.2988732320199949 \t 1.089220478652022\n",
      "************* 5 번차 epoch *************\n",
      "1.2970672789506312 \t 0.9851142642633629\n",
      "2.7076517220467076 \t 1.0191113453178078\n",
      "1.717503632530371 \t 1.087307383775543\n",
      "0.010732995953743702 \t 1.0378584654284653\n",
      "1.6223219864319038 \t 1.0421192313849712\n",
      "0.5983523605544286 \t 1.065711986739089\n",
      "3.6770946589955216 \t 1.0324987049167218\n",
      "0.33578699660860856 \t 1.0421534083773323\n",
      "************* 6 번차 epoch *************\n",
      "6.909672664214158 \t 0.8316459336743003\n",
      "0.5412937920271447 \t 1.05225022819261\n",
      "0.5173767348668407 \t 1.1173748773576082\n",
      "0.0002536472321091479 \t 1.0959336552532999\n",
      "1.8347061443168793 \t 1.1050255320125593\n",
      "3.87957701964076 \t 1.0858449927874199\n",
      "0.034224039279673796 \t 1.0723378156344174\n",
      "0.5928050379944414 \t 1.0593258021915246\n",
      "************* 7 번차 epoch *************\n",
      "0.014904020820778761 \t 1.1063262703667847\n",
      "0.3581391562422032 \t 0.9998012040569987\n",
      "0.1777792795674968 \t 0.9957458584682551\n",
      "0.2077783303675124 \t 1.0417120247706273\n",
      "0.3168592612346007 \t 1.0307674242730098\n",
      "0.0361508562333817 \t 1.0363118623479752\n",
      "0.24060471234138503 \t 1.0575592995116372\n",
      "0.1839052657522956 \t 1.0608036819201931\n",
      "************* 8 번차 epoch *************\n",
      "2.1505301563406767 \t 1.0796600967913843\n",
      "2.09470552864408 \t 1.0199990349155703\n",
      "0.2712228218018281 \t 0.9605446617311653\n",
      "0.5925299002786257 \t 0.9816056771093584\n",
      "0.5435467646906523 \t 1.0088513421930763\n",
      "2.1459373604915655 \t 1.0086904310429712\n",
      "1.6458932371590396 \t 1.0426309799908484\n",
      "0.49647736816599747 \t 1.0545045507861237\n",
      "************* 9 번차 epoch *************\n",
      "5.344504458747484 \t 1.1582022538702539\n",
      "0.01742548890055465 \t 1.148891099924984\n",
      "0.04678600443157652 \t 1.116752101914507\n",
      "1.1082862783342837 \t 1.101475299146872\n",
      "0.2776646289912061 \t 1.0662041517541165\n",
      "2.3634019094517216 \t 1.064131618079745\n",
      "0.11834415824898463 \t 1.0471553805647433\n",
      "0.6762219969742803 \t 1.0516599204945287\n",
      "************* 10 번차 epoch *************\n",
      "0.4040619905952021 \t 1.042472679702191\n",
      "0.9478599160794423 \t 1.0824517166975298\n",
      "0.0522411440666936 \t 1.1354122526668762\n",
      "0.5293332842029357 \t 1.0890365671225548\n",
      "0.7632306776086274 \t 1.062947501130576\n",
      "0.008046881907461058 \t 1.032708592156764\n",
      "2.050879915655512 \t 1.0123867437230976\n",
      "2.0419027555518494 \t 1.046066932223565\n"
     ]
    }
   ],
   "source": [
    "for j in range(1,10+1):\n",
    "    print('*************',j,'번차 epoch *************')\n",
    "    data=np.random.permutation(data)\n",
    "    X_batch= data[:,0]\n",
    "    y_batch= data[:,1]\n",
    "    X_batch=np.reshape(X_batch,(idx,size))\n",
    "    y_batch=np.reshape(y_batch,(idx,size))\n",
    "\n",
    "    number_minibatch= np.int(np.ceil(X_batch.shape[0]/minibatch_size))\n",
    "    \n",
    "    avglo=0\n",
    "    for i in range(1,number_minibatch+1):\n",
    "        X_batch_temp=X_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "        y_temp=y_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "        loss=model.forward(X_batch_temp,y_temp)\n",
    "        avglo+=loss\n",
    "        if i % 100 ==0:\n",
    "            print(loss,'\\t',avglo/(i))\n",
    "            #avglo=0\n",
    "        model.backward(X_batch_temp,y_temp)\n",
    "        # print(model.w_grad)\n",
    "        # print(model.b_grad)\n",
    "    #     print(model.W)\n",
    "    #     print(model.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(data,idx,minibatch_size, epoch_size):\n",
    "    global W\n",
    "    global b\n",
    "    dat_list=[]\n",
    "#     X_batch= data[:,0]\n",
    "#     y_batch= data[:,1]\n",
    "#     X_batch=np.reshape(X_batch,(idx,size))\n",
    "#     y_batch=np.reshape(y_batch,(idx,size))\n",
    "\n",
    "    number_minibatch= np.int(np.ceil(data.shape[0]/minibatch_size))\n",
    "#     W=np.random.uniform(-R,R,size=size)\n",
    "#     b=np.random.uniform(-R,R,size=1)\n",
    "    \n",
    "    for j in range(1,epoch_size+1):\n",
    "        print('*************',j,'번차 epoch *************')\n",
    "        data=np.random.permutation(data)\n",
    "        X_batch= data[:,0]\n",
    "        y_batch= data[:,1]\n",
    "        X_batch=np.reshape(X_batch,(idx,size))\n",
    "        y_batch=np.reshape(y_batch,(idx,size))\n",
    "        \n",
    "        number_minibatch= np.int(np.ceil(X_batch.shape[0]/minibatch_size))\n",
    "    \n",
    "    #    assert X_batch.shape[0] == y_batch.shape[0]\n",
    "    #    assert X_batch.shape[1] == weights['W'].shape[0]\n",
    "        \n",
    "        for i in range(1, number_minibatch+1):\n",
    "            X_batch_temp=X_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "            y_temp=y_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "            \n",
    "            N=W*X_batch_temp\n",
    "            f= N+b\n",
    "            loss=np.mean(np.power(y_temp-f,2))\n",
    "            if i==1:\n",
    "                print('loss',loss)\n",
    "            forward_info['X']= X_batch_temp\n",
    "            forward_info['N']= N       # \n",
    "            forward_info['f']= f       # 예측값\n",
    "            forward_info['y']= y_temp # 실제값\n",
    "\n",
    "            # 전체코드로 본 도함수 계산과정\n",
    "            batch_size=forward_info['X'].shape[0]\n",
    "            dJdf=-2*(forward_info['y']-forward_info['f'])\n",
    "            dfdN=np.ones_like(forward_info['N']) \n",
    "            dfdB=np.ones_like(forward_info['N'])\n",
    "            dJdN=dJdf*dfdN \n",
    "            dNdW=np.transpose(forward_info['X'],(1,0))\n",
    "\n",
    "            dJdW=np.dot(dNdW, dJdN)\n",
    "            dLdB=(dJdf*dfdB).sum(axis=0)\n",
    "\n",
    "            loss_grad['W']=dJdW\n",
    "            loss_grad['B']=dLdB\n",
    "\n",
    "#             for key in weights.keys():\n",
    "#                 weights[key]=weights[key]- 0.00001 * loss_grad[key]\n",
    "            W=W - 0.00001 * loss_grad['W']\n",
    "            b=b - 0.00001 * loss_grad['B']\n",
    "        N=W*X_batch\n",
    "        f= N+b\n",
    "        loss=np.mean(np.power(y_batch-f,2))\n",
    "        print('Loss',loss)\n",
    "      \n",
    "        print('=================================')\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_data\n",
      "************* 1 번차 epoch *************\n",
      "loss 1.0233416278338576\n",
      "Loss 0.9882879332784041\n",
      "=================================\n",
      "************* 2 번차 epoch *************\n",
      "loss 1.5451502438276683\n",
      "Loss 0.9873357327667032\n",
      "=================================\n",
      "************* 3 번차 epoch *************\n",
      "loss 1.418639155198556\n",
      "Loss 0.9869866452882351\n",
      "=================================\n",
      "************* 4 번차 epoch *************\n",
      "loss 1.1491791136524265\n",
      "Loss 0.986984066069048\n",
      "=================================\n",
      "************* 5 번차 epoch *************\n",
      "loss 0.39157975952536495\n",
      "Loss 0.9869806865020484\n",
      "=================================\n",
      "************* 6 번차 epoch *************\n",
      "loss 0.8882260005107062\n",
      "Loss 0.9869509127034225\n",
      "=================================\n",
      "************* 7 번차 epoch *************\n",
      "loss 0.5494115320689925\n",
      "Loss 0.986959271268826\n",
      "=================================\n",
      "************* 8 번차 epoch *************\n",
      "loss 0.5201336393579441\n",
      "Loss 0.9869582606689452\n",
      "=================================\n",
      "************* 9 번차 epoch *************\n",
      "loss 1.06729614104604\n",
      "Loss 0.9869490022939055\n",
      "=================================\n",
      "************* 10 번차 epoch *************\n",
      "loss 1.2747636681136876\n",
      "Loss 0.986950402453556\n",
      "=================================\n",
      "************* 11 번차 epoch *************\n",
      "loss 1.4151873240730999\n",
      "Loss 0.9869489906361721\n",
      "=================================\n",
      "************* 12 번차 epoch *************\n",
      "loss 0.7773293651625085\n",
      "Loss 0.9869712813688362\n",
      "=================================\n",
      "************* 13 번차 epoch *************\n",
      "loss 1.4078949169286985\n",
      "Loss 0.9869668651808309\n",
      "=================================\n",
      "************* 14 번차 epoch *************\n",
      "loss 0.9355287075770067\n",
      "Loss 0.9869511500137998\n",
      "=================================\n",
      "************* 15 번차 epoch *************\n",
      "loss 0.8383998661829594\n",
      "Loss 0.9869521788447478\n",
      "=================================\n",
      "************* 16 번차 epoch *************\n",
      "loss 0.6793898891178433\n",
      "Loss 0.9869625231069842\n",
      "=================================\n",
      "************* 17 번차 epoch *************\n",
      "loss 0.5537574836087571\n",
      "Loss 0.986960779482302\n",
      "=================================\n",
      "************* 18 번차 epoch *************\n",
      "loss 1.1000241992300517\n",
      "Loss 0.9869502863672663\n",
      "=================================\n",
      "************* 19 번차 epoch *************\n",
      "loss 1.3743986167917894\n",
      "Loss 0.9869488496207703\n",
      "=================================\n",
      "************* 20 번차 epoch *************\n",
      "loss 0.7251725208467452\n",
      "Loss 0.9869624811441913\n",
      "=================================\n",
      "************* 21 번차 epoch *************\n",
      "loss 0.7246761344449031\n",
      "Loss 0.9869603196756995\n",
      "=================================\n",
      "************* 22 번차 epoch *************\n",
      "loss 0.9512473189957232\n",
      "Loss 0.9869486576838774\n",
      "=================================\n",
      "************* 23 번차 epoch *************\n",
      "loss 0.6955392705655575\n",
      "Loss 0.9869500642997938\n",
      "=================================\n",
      "************* 24 번차 epoch *************\n",
      "loss 0.7866476053328986\n",
      "Loss 0.9869625544422395\n",
      "=================================\n",
      "************* 25 번차 epoch *************\n",
      "loss 1.4281726090602729\n",
      "Loss 0.9870236613991225\n",
      "=================================\n",
      "************* 26 번차 epoch *************\n",
      "loss 1.089983463199358\n",
      "Loss 0.986982503238064\n",
      "=================================\n",
      "************* 27 번차 epoch *************\n",
      "loss 1.2599028528969556\n",
      "Loss 0.9869521372162547\n",
      "=================================\n",
      "************* 28 번차 epoch *************\n",
      "loss 0.8998144567238342\n",
      "Loss 0.9869509954618169\n",
      "=================================\n",
      "************* 29 번차 epoch *************\n",
      "loss 0.9183320579402461\n",
      "Loss 0.9869487430766197\n",
      "=================================\n",
      "************* 30 번차 epoch *************\n",
      "loss 0.5193049359680303\n",
      "Loss 0.9869531576885116\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "print('Train_data')\n",
    "linear_regression(train_data_set,train_idx,20,30)\n",
    "\n",
    "# print('\\ndev_data')\n",
    "# linear_regression(dev_data_set,dev_idx,20,30)\n",
    "\n",
    "# print('\\nTest_data')\n",
    "# linear_regression(test_data_set,test_idx,20,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
