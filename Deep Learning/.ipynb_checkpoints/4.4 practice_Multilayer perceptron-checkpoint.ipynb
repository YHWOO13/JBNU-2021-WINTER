{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 MLP - Stochastic Gradient Descent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    " Author: Yoonhyuck WOO / JBNU_Industrial Information system Engineering\n",
    " Date; 3. 19. 2020 - 4. 04. 2021\n",
    " Title: Artificial Intelligence_Project 2\n",
    " Professor: Seung-Hoon Na'''\n",
    "  \n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "mnist = datasets.fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mnist.data.shape, mnist.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mnist.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "data=list(zip(mnist.data,mnist.target))\n",
    "#data=np.concatenate((mnist.data,mnist.target),axis=1)\n",
    "data=np.array(data)\n",
    "x=data[:,0]\n",
    "x=np.array(x)\n",
    "#y=data[:,1]\n",
    "print(x.shape)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "mnist.target = encoder.fit_transform(mnist.target.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59500, 784)\n",
      "(59500, 10)\n",
      "(7000, 784)\n",
      "(7000, 10)\n",
      "(3500, 784)\n",
      "(3500, 10)\n"
     ]
    }
   ],
   "source": [
    "         \n",
    "train_idx=int(data.shape[0]*0.85)\n",
    "dev_idx=int(data.shape[0]*0.05)\n",
    "test_idx=int(data.shape[0]*0.1)\n",
    "\n",
    "data=np.array(mnist.data)\n",
    "target=np.array(mnist.target)\n",
    "\n",
    "train_x=data[0:train_idx,:]\n",
    "test_x=data[train_idx:train_idx+test_idx,:]\n",
    "dev_x=data[train_idx+test_idx:train_idx+test_idx+dev_idx,:]\n",
    "\n",
    "\n",
    "train_y=target[0:train_idx,:]\n",
    "test_y=target[train_idx:train_idx+test_idx,:]\n",
    "dev_y=target[train_idx+test_idx:train_idx+test_idx+dev_idx,:]\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "print(dev_x.shape)\n",
    "print(dev_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = list(zip(train_x, train_y))\n",
    "np.random.shuffle(combined)\n",
    "train_x[:], train_y[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make relu class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relu():\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, affine, dout):\n",
    "        mask = (affine<=0)\n",
    "        dout[mask]= 0\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self):\n",
    "        self.a = 0\n",
    "        \n",
    "    def forward(self,W, X, b):\n",
    "        \n",
    "        self.a = np.dot(X,W) + b\n",
    "        \n",
    "        return self.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make softmax class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softmax():    \n",
    "    def __init__(self):\n",
    "        self.r = 0\n",
    "        self.exp_o = 0\n",
    "        self.sum_exp_o = 0\n",
    "        \n",
    "    def forward(self,h,U,d):\n",
    "        self.r = np.dot(U, h) + d\n",
    "\n",
    "        delta = np.max(self.r)\n",
    "        \n",
    "        self.exp_o = np.exp(self.r - delta)\n",
    "        self.sum_exp_o = np.sum(self.exp_o)\n",
    "        self.softmax = self.exp_o / self.sum_exp_o\n",
    "        \n",
    "        return self.softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Cross_entropy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CE():\n",
    "    def __init__(self):\n",
    "        self.result = 0\n",
    "        \n",
    "    def forward(self, softMAX, y):\n",
    "        # cross_entropy + 마이너스 무한대가 생기지 않도록 만듦\n",
    "        delta = 1e-7\n",
    "        \n",
    "        return - np.sum(y * np.log(softMAX + delta))\n",
    "        \n",
    "    def backward(self, y, softMAX):\n",
    "        batch_size = y.shape[0]\n",
    "        dJdR = (softMAX-y) / batch_size\n",
    "        return dJdR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Layer:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 th Dimenson "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ": 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 th Dimenson "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ": 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 th Dimenson "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ": 30\n",
      "Minibatch size(10~500):  100\n",
      "epoch size:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* 1 번차 epoch *************\n",
      "[[ 1.12002615  6.09750594 -2.8570284  -5.87707347 -1.89493448 -2.89185248\n",
      "  -5.8617735  -6.89049873  1.10377426  7.09772245]\n",
      " [-4.87739184  8.09506437 -6.85773466  8.1225601   4.10435495  7.102486\n",
      "  -8.85796965  3.1124261   8.10246001 -4.90290047]\n",
      " [ 0.13389578  5.10328612  9.16424025 -1.87146833 -6.88173596 -3.8836467\n",
      "  -1.85149246 -7.88168717 -3.89077319  6.10724343]\n",
      " [ 0.12739381 -3.90290706  1.14949356  6.12012447 -8.88262959 -4.89451931\n",
      "  -4.85498147  6.1194394  -4.89048411 -6.89850472]\n",
      " [ 1.12578672  4.09220925  4.14720285  9.11771995 -9.88764264  6.10612514\n",
      "   0.14537088  5.11856937 -0.89560404  9.09852871]\n",
      " [ 1.12671982 -0.90051713 -9.85617689  5.12082902  6.10897044  2.10927513\n",
      "   0.13978429 -4.88237785  7.10874602  4.10592644]\n",
      " [-2.86744948  9.09528246  9.15527214 -7.87167316 -2.88709617  7.10662811\n",
      "  -8.85695444  7.11201073 -4.88457745 -7.89569234]\n",
      " [ 0.12382065  2.10469867  5.14768747  0.12879416 -1.88727726  0.10831088\n",
      "   3.14231364  0.11768835 -8.88779873 -3.89335535]\n",
      " [ 5.13064708 -8.89955432 -4.85503359  3.12506265 -9.88463914  4.10771507\n",
      "   9.14618088  7.11732379  9.09700485 -8.89186228]\n",
      " [ 8.12788979 -3.89537178  3.15347149  9.12354172  5.10354843  3.10381604\n",
      "   3.14486461 -5.88608042  3.10686297  6.10316165]\n",
      " [-7.87388571  1.09942136  0.15489927 -3.87847683  5.11068669 -2.89244965\n",
      "  -2.85608363 -3.88005823  8.10129349 -6.89439083]\n",
      " [ 0.12102123 -1.90614348 -7.86001518 -2.88350036 -0.89581151  9.09783668\n",
      "   8.12814127  6.11078644  0.09843089 -2.89825356]\n",
      " [ 1.11812072 -2.8948826   4.13941835 -5.88178924  3.10910595  4.10490864\n",
      "  -5.86171799 -1.88614612 -7.88799365 -1.89884029]\n",
      " [ 0.12471974  5.09486099 -0.8520606   7.12495821 -2.89597159 -4.89145865\n",
      "   8.13677196  2.11715544 -6.89167187 -1.89894987]\n",
      " [ 5.13013385 -8.88842171 -6.84136495 -1.87643618  4.10931674 -2.88881024\n",
      "   2.14794297 -4.88042929  0.11079246  3.10164824]\n",
      " [-2.88508679  3.10024345 -9.86335425  6.1095645   0.10131737  4.09802396\n",
      "   0.12645093  7.11115168  1.09963129  7.09113063]\n",
      " [ 5.12476032 -4.90355405 -7.85520148 -1.87807364 -4.88881528 -5.89140448\n",
      "  -3.86234199  0.12364647  2.10404051  4.10601462]\n",
      " [ 0.12495452  2.09330418 -7.85809526 -0.88449925  8.09821691 -6.89529067\n",
      "  -2.864743   -8.88373522 -9.89132695 -4.90033607]\n",
      " [ 1.12837617 -2.89439691 -8.85063135 -8.87401857  9.10364154 -1.88983125\n",
      "   4.13941995  2.11897767  3.10872103 -3.89609621]\n",
      " [ 6.12383766 -1.90496906  9.14381431 -1.87646331 -1.88929413 -9.89487353\n",
      "   5.13762933  2.11192    -8.89204307 -6.90288322]\n",
      " [-4.89014378  2.08759826 -7.87104026 -5.89693057  6.08959603  2.0952766\n",
      "   0.11956207  2.1007119   8.09033831  2.08462338]\n",
      " [-6.8728178  -4.90083019 -8.85555966 -7.8745085  -1.88812003  9.10233658\n",
      "  -5.85290866 -6.88767786  6.10212891  8.09641458]\n",
      " [ 2.12084695 -2.90784104  7.14532909  6.11133115  4.10676038  7.10115693\n",
      "  -5.87087324  0.11188483  9.09947448  2.09849825]\n",
      " [ 0.12226294 -5.90671572  1.14293041 -5.88435993  2.10197945 -7.89884873\n",
      "  -2.86416713  1.11058231  5.09925602 -4.90690256]\n",
      " [-3.8766379   0.10184638 -0.85803009  3.12155572  3.10320845 -9.89648184\n",
      "   3.13747101 -9.88414651 -0.89806455  6.09891517]\n",
      " [ 9.12600538  5.09928389 -6.84361817  5.12465315  6.10940416 -1.89121967\n",
      "   7.13875826 -2.88258162  6.10505565  3.10610142]\n",
      " [-6.87864446 -4.90478874 -7.86111196  8.11586843 -7.89643212  3.09873961\n",
      "  -0.86175072  2.10085546 -3.89821227 -4.91029213]\n",
      " [-6.87410739  4.09832973 -0.85548358 -2.88109963  4.10728611 -5.89535174\n",
      "  -6.86623581  3.11047418  8.09853238 -0.89780013]\n",
      " [ 5.1326714   8.09874052 -2.84592413 -5.8759728   9.10759486  9.10962404\n",
      "  -2.85765432 -3.87732173 -4.88936051  2.10659667]\n",
      " [-8.87964752  9.09187237  4.13750756 -8.88501832  4.10544801  2.09929523\n",
      "   1.13180618  3.11563252  3.10232792  3.09996024]]\n",
      "최종\n",
      "959026.6912320211\n",
      "************* 2 번차 epoch *************\n",
      "[[ 1.25727881  6.20106342 -2.7025416  -5.74697555 -1.78132805 -2.7739749\n",
      "  -5.71955708 -6.76288587  1.21945066  7.20374051]\n",
      " [-4.75065995  8.18665266 -6.7086761   8.24555059  4.20165707  7.21422831\n",
      "  -8.72518369  3.22219557  8.20772809 -4.80548694]\n",
      " [ 0.250112    5.19569068  9.29598552 -1.75435106 -6.77746877 -3.78033171\n",
      "  -1.72336013 -7.77348433 -3.79055078  6.19676017]\n",
      " [ 0.24928661 -3.80423466  1.29038675  6.23285226 -8.77827092 -4.79276777\n",
      "  -4.72230368  6.22821017 -4.78513322 -6.79732981]\n",
      " [ 1.2493991   4.18382701  4.29392619  9.22837861 -9.78316945  6.20532145\n",
      "   0.27895583  5.23022033 -0.79310754  9.18684851]\n",
      " [ 1.25062562 -0.79910778 -9.70404429  5.24182996  6.21772204  2.21942203\n",
      "   0.27632627 -4.76910744  7.21982735  4.20423884]\n",
      " [-2.74439777  9.18638437  9.29706656 -7.74970934 -2.7776247   7.21174835\n",
      "  -8.72240045  7.22584762 -4.78022738 -7.7965556 ]\n",
      " [ 0.24463854  2.20137499  5.29613144  0.25327326 -1.78579853  0.21076564\n",
      "   3.27233263  0.22528264 -8.77634564 -3.79675045]\n",
      " [ 5.25084993 -8.80427301 -4.70909826  3.24403326 -9.77855253  4.21179817\n",
      "   9.2794066   7.2253297   9.19263805 -8.79388402]\n",
      " [ 8.24911508 -3.79594689  3.29577235  9.23915403  5.20089211  3.20596259\n",
      "   3.27629341 -5.77848163  3.21197044  6.19833393]\n",
      " [-7.75216073  1.19135897  0.29013847 -3.76350719  5.21377322 -2.79028003\n",
      "  -2.72507672 -3.76858848  8.20240459 -6.79153949]\n",
      " [ 0.25085159 -1.80804259 -7.71329581 -2.76547956 -0.79061814  9.2088351\n",
      "   8.26580741  6.21786062  0.20275404 -2.79832263]\n",
      " [ 1.24369337 -2.79736847  4.29001825 -5.76068623  3.22382882  4.21598181\n",
      "  -5.72851613 -1.76951396 -7.7761565  -1.79306381]\n",
      " [ 0.24737666  5.19176198 -0.7092118   7.2424432  -2.79236423 -4.78609834\n",
      "   8.27465293  2.22966737 -6.78363004 -1.80404501]\n",
      " [ 5.25691677 -8.78663388 -6.69474556 -1.75469254  4.21754323 -2.77962686\n",
      "   2.28635439 -4.76742451  0.22519071  3.20127755]\n",
      " [-2.75784969  3.20091645 -9.71546902  6.22700929  0.20764577  4.20832995\n",
      "   0.26277745  7.22137219  1.20220614  7.18739137]\n",
      " [ 5.24237384 -4.8104259  -7.71777045 -1.76319175 -4.78472417 -5.79014846\n",
      "  -3.73204587  0.22207517  2.20147681  4.19979301]\n",
      " [ 0.24959082  2.19603318 -7.7092083  -0.76522202  8.20103986 -6.79010353\n",
      "  -2.72883393 -8.77407846 -9.78007044 -4.8065651 ]\n",
      " [ 1.24016792 -2.808272   -8.71947151 -8.7647638   9.19947603 -1.7919759\n",
      "   4.2574278   2.22331328  3.20410636 -3.80654116]\n",
      " [ 6.25197905 -1.80161458  9.28852092 -1.75572683 -1.7824107  -9.78280892\n",
      "   5.27319383  2.22403914 -8.77995966 -6.80406454]\n",
      " [-4.77241679  2.18291737 -7.72370629 -5.7838633   6.19577426  2.20324034\n",
      "   0.25707739  2.21545212  8.19505095  2.1871335 ]\n",
      " [-6.74385607 -4.79999007 -8.6962378  -7.74082853 -1.77415152  9.21324782\n",
      "  -5.71187513 -6.76551605  6.21179864  8.200432  ]\n",
      " [ 2.24702162 -2.79855215  7.30505793  6.23801355  4.21885221  7.22091234\n",
      "  -5.7242086   0.23052579  9.20975982  2.20812717]\n",
      " [ 0.24035728 -5.8112008   1.28830636 -5.76357031  2.20994215 -7.793399\n",
      "  -2.73168962  1.22094595  5.20495778 -4.81068384]\n",
      " [-3.74956322  0.20468577 -0.70326556  3.24129001  3.20992992 -9.78594759\n",
      "   3.27429845 -9.76369017 -0.78876694  6.20314374]\n",
      " [ 9.25532812  5.19945613 -6.68936837  5.24726565  6.22234455 -1.78138496\n",
      "   7.26977744 -2.76362673  6.21689158  3.21146753]\n",
      " [-6.75184634 -4.81239202 -7.71428424  8.22524701 -7.78788269  3.20806059\n",
      "  -0.73273746  2.20759788 -3.7910826  -4.8135857 ]\n",
      " [-6.74830501  4.19810394 -0.71036636 -2.75894211  4.21362373 -5.78870115\n",
      "  -6.72694199  3.2222712   8.20287377 -0.79777716]\n",
      " [ 5.25842142  8.19672496 -2.6958513  -5.75942338  9.20682478  9.20915494\n",
      "  -2.72274472 -3.76844075 -4.7805289   2.20260889]\n",
      " [-8.75288576  9.17569342  4.27687564 -8.76738203  4.2068679   2.20101715\n",
      "   1.27031154  3.2301282   3.20397725  3.19702932]]\n",
      "최종\n",
      "959026.6912320211\n",
      "************* 3 번차 epoch *************\n",
      "[[ 1.38498192  6.2945396  -2.55454084 -5.6261284  -1.66873218 -2.66562436\n",
      "  -5.58506    -6.64488289  1.32447295  7.30071295]\n",
      " [-4.63859704  8.27997272 -6.57642442  8.3513198   4.29702354  7.30844975\n",
      "  -8.60800114  3.32710728  8.2966278  -4.71787942]\n",
      " [ 0.36561553  5.28675032  9.43739225 -1.63719623 -6.67062808 -3.6796268\n",
      "  -1.59785868 -7.66319918 -3.6878509   6.2900921 ]\n",
      " [ 0.36872564 -3.71070565  1.42396042  6.34282928 -8.67572063 -4.69177942\n",
      "  -4.59669174  6.33276628 -4.68809188 -6.70668189]\n",
      " [ 1.37423417  4.28315239  4.43652837  9.34643657 -9.6785021   6.31237156\n",
      "   0.41195821  5.34638412 -0.6887552   9.28430706]\n",
      " [ 1.37078109 -0.70683598 -9.57349462  5.35125155  6.31860144  2.31916354\n",
      "   0.3978838  -4.66182907  7.31404452  4.29456771]\n",
      " [-2.61806677  9.283233    9.43799099 -7.62500808 -2.66407699  7.31747096\n",
      "  -8.59076114  7.34050356 -4.67310186 -7.69423819]\n",
      " [ 0.37844758  2.30852452  5.44620355  0.37663487 -1.67047956  0.32246346\n",
      "   3.41360568  0.34641014 -8.66047309 -3.6950151 ]\n",
      " [ 5.37224765 -8.70496483 -4.569484    3.36865301 -9.66156806  4.31592282\n",
      "   9.41227365  7.34127497  9.29143206 -8.69526496]\n",
      " [ 8.37847333 -3.69495886  3.4470347   9.35992307  5.30704989  3.31483772\n",
      "   3.4122426  -5.65922351  3.31979725  6.29983113]\n",
      " [-7.63183485  1.28505885  0.42915322 -3.64612954  5.31639922 -2.6859823\n",
      "  -2.59764887 -3.65576504  8.2972706  -6.69626496]\n",
      " [ 0.37838158 -1.70621134 -7.56233629 -2.63509501 -0.67456899  9.31891806\n",
      "   8.40504185  6.34320013  0.3104417  -2.69295129]\n",
      " [ 1.36405633 -2.70067051  4.43230289 -5.643669    3.33205391  4.31501764\n",
      "  -5.59856599 -1.65356751 -7.66718081 -1.6975258 ]\n",
      " [ 0.38104396  5.30623204 -0.55730896  7.36716136 -2.67495697 -4.67329481\n",
      "   8.41383636  2.35454242 -6.66959496 -1.69746799]\n",
      " [ 5.37933989 -8.68905451 -6.56103555 -1.63774306  4.31481301 -2.67743686\n",
      "   2.41296766 -4.65664399  0.32394125  3.29151717]\n",
      " [-2.63294507  3.30046366 -9.57079829  6.35210211  0.31842329  4.3155366\n",
      "   0.39878996  7.33558246  1.30838521  7.28196747]\n",
      " [ 5.3779934  -4.70124666 -7.56431344 -1.63028001 -4.66987287 -5.67741079\n",
      "  -3.58815469  0.34513157  2.31183642  4.30189661]\n",
      " [ 0.37570475  2.29659677 -7.56458353 -0.64208464  8.30777291 -6.68046298\n",
      "  -2.5893676  -8.65077737 -9.67135444 -4.71030291]\n",
      " [ 1.36234354 -2.71017113 -8.58300415 -8.64356686  9.29966476 -1.6836323\n",
      "   4.38062281  2.33667008  3.30563713 -3.70941041]\n",
      " [ 6.37407973 -1.69957739  9.43682535 -1.63583015 -1.67399881 -9.67270007\n",
      "   5.41397725  2.34265653 -8.66945859 -6.70291762]\n",
      " [-4.65186501  2.27951818 -7.58577942 -5.66407977  6.29981638  2.30384952\n",
      "   0.38752096  2.33097941  8.29148907  2.28366828]\n",
      " [-6.62315018 -4.71058807 -8.55627929 -7.62081665 -1.66635799  9.31234742\n",
      "  -5.58098197 -6.65158041  6.31375866  8.29556248]\n",
      " [ 2.35543061 -2.70467025  7.43055928  6.344587    4.31696011  7.31866833\n",
      "  -5.6064423   0.33794857  9.29761777  2.29701067]\n",
      " [ 0.36870035 -5.71690719  1.42809198 -5.64246253  2.3191401  -7.68702007\n",
      "  -2.59241735  1.33283627  5.30714576 -4.71170651]\n",
      " [-3.61309215  0.31797225 -0.54303947  3.38501423  3.32805549 -9.66205094\n",
      "   3.42303401 -9.63548507 -0.67781351  6.30859413]\n",
      " [ 9.38021174  5.30070461 -6.54383946  5.36478172  6.33086057 -1.67464386\n",
      "   7.40347369 -2.64540967  6.32286383  3.31103338]\n",
      " [-6.62375582 -4.70955303 -7.56874799  8.35294618 -7.6744604   3.31515156\n",
      "  -0.59825351  2.32720331 -3.6757859  -4.70928881]\n",
      " [-6.62489488  4.29771498 -0.57493709 -2.64420576  4.31686775 -5.68487437\n",
      "  -6.59338984  3.33271885  8.3001957  -0.7015787 ]\n",
      " [ 5.37527104  8.29246379 -2.5602267  -5.64612701  9.3042377   9.30518166\n",
      "  -2.59534447 -3.65534685 -4.67969551  2.29614606]\n",
      " [-8.62851048  9.27265495  4.41623762 -8.64195597  4.3175513   2.30538568\n",
      "   1.40221383  3.34563353  3.31014432  3.29593564]]\n",
      "최종\n",
      "959026.691232021\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "ce = CE()\n",
    "Relu = relu()\n",
    "SOFTMAX = softmax()\n",
    "\n",
    "layer=[]\n",
    "param_w = []\n",
    "param_b = []\n",
    "affine = []\n",
    "\n",
    "grad_w = []\n",
    "grad_b = []\n",
    "grad_affine = []\n",
    "\n",
    "L = int(input('Layer: '))\n",
    "\n",
    "for i in range(L):\n",
    "    print(i+1,'th Dimenson', end = ' ') \n",
    "    d=int(input(':'))\n",
    "    \n",
    "    layer.append(d)\n",
    "    \n",
    "length = len(layer)\n",
    "\n",
    "for i in range(length):\n",
    "    param_w.append(0)\n",
    "    param_b.append(0)\n",
    "    grad_w.append(0)\n",
    "    grad_b.append(0)\n",
    "for i in range(length+1):\n",
    "    affine.append(0)\n",
    "    grad_affine.append(0)\n",
    "\n",
    "minibatch_size = int(input('Minibatch size(10~500): '))\n",
    "epoch_size = int(input('epoch size: '))\n",
    "#iter_per_epoch= max(X[:].shape[0] / minibatch_size, 1)\n",
    "\n",
    "def learning(X,y, minibatch_size, epoch_size, learning_rate):\n",
    "    d = np. random.uniform(-10,10,10)\n",
    "    U = np. random.randint(-10,10,(layer[length-1],y.shape[1]))\n",
    "    for e in range(1,epoch_size+1):\n",
    "        print('*************',e,'번차 epoch *************')\n",
    "        \n",
    "        combined = list(zip(X, y))\n",
    "        np.random.shuffle(combined)\n",
    "        X[:], y[:] = zip(*combined)\n",
    "\n",
    "        number_minibatch= np.int(np.ceil(X.shape[0] / minibatch_size))\n",
    "        \n",
    "        for n in range(1, number_minibatch+1):\n",
    "            X_temp=X[minibatch_size*n-(minibatch_size-1)-1:minibatch_size*n]\n",
    "            X_temp = X_temp / 255\n",
    "            y_temp=y[minibatch_size*n-(minibatch_size-1)-1:minibatch_size*n]\n",
    "            \n",
    "            ########################## MLP ########################## \n",
    "            for i in range(length):\n",
    "                #print('-------------',i+1,'번째 layer-------------')\n",
    "                if (i == 0):\n",
    "                    x = X_temp\n",
    "                    W = np. random.uniform(-2,2,(784,layer[i]))\n",
    "                    b = np. random.uniform(-2,2,layer[i])\n",
    "                    a = model.forward(W, x, b)\n",
    "                    x = Relu.forward(a)\n",
    "                    \n",
    "                    param_w[i] = W\n",
    "                    param_b[i] = b\n",
    "                    affine[i] = a\n",
    "                else:\n",
    "                    W = np. random.uniform(-2,2,(np.array(x).shape[1],layer[i]))\n",
    "                    b = np. random.uniform(-2,2,layer[i])\n",
    "                    a = model.forward(W, x, b)\n",
    "                    Relu.forward(a)\n",
    "\n",
    "                    param_w[i] = W\n",
    "                    param_b[i] = b\n",
    "                    affine[i] = a\n",
    "                    \n",
    "                    x = Relu.forward(a)\n",
    "                    \n",
    "            o = SOFTMAX.forward(U,x,d) # softmax\n",
    "            J = ce.forward(o, y_temp) # cross_Entropy\n",
    "            \n",
    "            ############# BACKWARD #############\n",
    "            dJdR = ce.backward(y_temp,o) #softmax & cross_Entropy loss\n",
    "            dJdU = np.dot(np.transpose(x),dJdR)\n",
    "            dJd_ = np.dot(dJdR,np.transpose(U))\n",
    "            dJdd = np.ones_like(d)\n",
    "\n",
    "            param_w.reverse()\n",
    "            param_b.reverse()\n",
    "            affine.reverse()\n",
    "            affine[length] = X_temp\n",
    "\n",
    "            for x in range(length):\n",
    "                #print('------------- from back',x+1,'번째 backpropagation-------------')\n",
    "                if (x != 0):\n",
    "                    dJd_ = np.dot(dJd_,np.transpose(param_w[x-1]))\n",
    "    \n",
    "                dJdw = np.dot(np.transpose(affine[x+1]),dJd_)\n",
    "                dJdb = np.ones_like(param_b[x])\n",
    "                grad_w.append(dJdw)\n",
    "                grad_b.append(dJdb)\n",
    "                \n",
    "            #print('------------- from back',length,'번째 backpropagation-------------')\n",
    "            dJd_ = np.dot(dJd_,np.transpose(param_w[length-1]))\n",
    "            dJdw = np.dot(np.transpose(X_temp),dJd_)\n",
    "            dJdb = np.ones_like(param_b[length-1])\n",
    "            grad_w.append(dJdw)\n",
    "            grad_b.append(dJdb)\n",
    "            \n",
    "            for key in range(length-1):\n",
    "                param_w[key] = param_w[key]- learning_rate * grad_w[key]\n",
    "                param_b[key] = param_b[key]- learning_rate * grad_b[key]\n",
    "            U = U - learning_rate * dJdU\n",
    "            d = d - learning_rate * dJdd\n",
    "            \n",
    "        param_w.reverse()\n",
    "        param_b.reverse()\n",
    "\n",
    "    \n",
    "        ### J출력 ###\n",
    "        for r in range(length):\n",
    "            if (r == 0):\n",
    "                x = X[:]\n",
    "                a = model.forward(param_w[r], X, param_b[r])\n",
    "                x = Relu.forward(a)\n",
    "            else:\n",
    "                a = model.forward(param_w[r], x, param_b[r])\n",
    "                x = Relu.forward(a)\n",
    "        print(U)\n",
    "        o = SOFTMAX.forward(U,x,d) # softmax\n",
    "        J = ce.forward(o, y) # cross_Entropy\n",
    "        \n",
    "        \n",
    "        print('최종')\n",
    "        print(J)\n",
    "        \n",
    "train_ = learning(train_x, train_y, minibatch_size, epoch_size, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
