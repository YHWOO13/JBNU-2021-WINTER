{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlis = []\n",
    "ylis = []\n",
    "flis = [] \n",
    "wlis = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=10\n",
    "size=1\n",
    "weights={}\n",
    "#data_set={}    \n",
    "loss_grad={}    # dJdW, dJdB 저장공간\n",
    "forward_info={} # 순방향 저장공간\n",
    "batch={}\n",
    "\n",
    "W= np.random.uniform(-R,R,size=size)\n",
    "b= np.random.uniform(-R,R,size=1)\n",
    "\n",
    "for i in range(1000):\n",
    "    x = np.random.uniform(-R,R,size=size)\n",
    "    y = np.random.normal(W*x+b,1,size=size)\n",
    "    xlis.append(x)\n",
    "    ylis.append(y)\n",
    "    flis.append(W*x+b)\n",
    "\n",
    "x=np.array(xlis)\n",
    "y=np.array(ylis)\n",
    "\n",
    "weights['W']=W\n",
    "weights['B']=b\n",
    "\n",
    "result=np.concatenate((x,y),axis=1)\n",
    "\n",
    "train_idx=int(result.shape[0]*0.85)\n",
    "dev_idx=int(result.shape[0]*0.05)\n",
    "test_idx=int(result.shape[0]*0.1)\n",
    "\n",
    "train_data_set=result[0:train_idx,:]\n",
    "test_data_set=result[train_idx:train_idx+test_idx,:]\n",
    "dev_data_set=result[train_idx+test_idx:train_idx+test_idx+dev_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22ecabc4488>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(xlis,ylis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.61725743]\n",
      "[-0.71854169]\n"
     ]
    }
   ],
   "source": [
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(850, 2)\n",
      "(850,)\n",
      "(850, 1)\n"
     ]
    }
   ],
   "source": [
    "data=train_data_set\n",
    "idx=train_idx\n",
    "minibatch_size=1\n",
    "data=np.random.permutation(data)\n",
    "\n",
    "#epoch\n",
    "print(data.shape)\n",
    "X_batch= data[:,0]\n",
    "print(X_batch.shape)\n",
    "y_batch= data[:,1]\n",
    "X_batch=np.reshape(X_batch,(idx,size))\n",
    "y_batch=np.reshape(y_batch,(idx,size))\n",
    "\n",
    "print(X_batch.shape)\n",
    "\n",
    "number_minibatch= np.int(np.ceil(X_batch.shape[0]/minibatch_size))\n",
    "\n",
    "#iteration\n",
    "# i=1\n",
    "# X_batch_temp=X_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "# y_temp=y_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self): #초깃값 설정해야 할 때\n",
    "        self.W=np.random.uniform(-R,R,size=size)\n",
    "        self.b=np.random.uniform(-R,R,size=1)\n",
    "        self.N=0\n",
    "        self.f=0\n",
    "        self.loss=0\n",
    "        self.w_grad=np.zeros(size)\n",
    "        self.b_grad=np.zeros(1)\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        print('W')\n",
    "        print(self.W)\n",
    "        \n",
    "        print('b')\n",
    "        print(self.b)\n",
    "        self.N = self.W*x\n",
    "        self.f = self.N+self.b\n",
    "        self.loss=np.mean(np.power(y-self.f,2))\n",
    "        \n",
    "#         print('w',self.W.shape)\n",
    "#         print(self.b.shape)\n",
    "#         print(x.shape)\n",
    "#         print(y.shape)\n",
    "#         print(self.N.shape)\n",
    "#         print(self.f.shape)\n",
    "#         print('loss',self.loss.shape)\n",
    "        \n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self,x,y):\n",
    "        batch_size=x.shape[0]\n",
    "        dJdf = 2*(self.f-y)/batch_size\n",
    "        #print(dJdf)\n",
    "        dfdN=np.ones_like(self.N) \n",
    "        #print('dfdN',dfdN)\n",
    "        dfdB=np.ones_like(self.N)\n",
    "        #print(dfdB)\n",
    "        \n",
    "        dJdN=dJdf*dfdN\n",
    "#         print('dJdN',dJdN.shape)\n",
    "        #print(dJdN)\n",
    "        dNdW=np.transpose(x,(1,0))\n",
    "        #print(dNdW)\n",
    "        dJdW=np.dot(dNdW, dJdN)\n",
    "#         print(dJdW.shape)\n",
    "        #print(dJdW)\n",
    "        dJdB=(dJdf*dfdB).sum(axis=0)\n",
    "        #print(dJdB)\n",
    "        self.w_grad=dJdW\n",
    "        self.b_grad=dJdB\n",
    "\n",
    "#         dJdW=2*(self.f-y)/batch_size*x\n",
    "#         dJdb=2*(self.f-y)/batch_size\n",
    "#         self.w_grad=sum(dJdW)\n",
    "#         self.b_grad=sum(dJdb)\n",
    "\n",
    "        self.W=self.W - 0.001 * self.w_grad\n",
    "        self.b=self.b - 0.001 * self.b_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.47496619]\n",
      "[-9.19373943]\n",
      "[0.]\n",
      "W\n",
      "[-6.47496619]\n",
      "b\n",
      "[-9.19373943]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48.878636292285975"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R=10\n",
    "size=1\n",
    "weights={}\n",
    "#data_set={}    \n",
    "loss_grad={}    # dJdW, dJdB 저장공간\n",
    "forward_info={} # 순방향 저장공간\n",
    "batch={}\n",
    "model=Model()\n",
    "print(model.W)\n",
    "print(model.b)\n",
    "print(model.b_grad)\n",
    "for i in range(1000):\n",
    "    x = np.random.uniform(-R,R,size=size)\n",
    "    y = np.random.normal(model.W*x+model.b,1,size=size)\n",
    "    xlis.append(x)\n",
    "    ylis.append(y)\n",
    "    flis.append(model.W*x+model.b)\n",
    "\n",
    "x=np.array(xlis)\n",
    "y=np.array(ylis)\n",
    "model.forward(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* 1 번차 epoch *************\n",
      "0.0004892759115479702 \t 13.375001751670126\n",
      "3.7932003048908065 \t 10.127096803686623\n",
      "7.120517958921674 \t 8.393168985510124\n",
      "14.812482914196194 \t 7.184110648276089\n",
      "2.267351193447741 \t 6.301492307352047\n",
      "0.06514102127675449 \t 5.673266404400896\n",
      "0.38941899924603246 \t 5.11903358539437\n",
      "2.649766252886864 \t 4.692745221464606\n",
      "************* 2 번차 epoch *************\n",
      "5.165448593569632 \t 1.3666624788843604\n",
      "3.1103042312745615 \t 1.3393848648838889\n",
      "0.001795681007026583 \t 1.2495986718766456\n",
      "0.12775115938430961 \t 1.262502689867242\n",
      "1.7911283645229281 \t 1.245364661137218\n",
      "0.09908667528057707 \t 1.2285680481495287\n",
      "0.11334011521420376 \t 1.2024633906953381\n",
      "0.05752905630536603 \t 1.1896303308430283\n",
      "************* 3 번차 epoch *************\n",
      "0.02765777136771625 \t 1.2099327101990949\n",
      "1.7175791032480139 \t 1.0699130195149718\n",
      "0.3114259777613636 \t 1.0200180230362328\n",
      "0.090265088452497 \t 0.9989735365076572\n",
      "0.1831584471548307 \t 1.0134403110447021\n",
      "0.11058407828739622 \t 1.0605835271824284\n",
      "1.8351583183983307 \t 1.0483629959130567\n",
      "0.8971803890514745 \t 1.053803758510253\n",
      "************* 4 번차 epoch *************\n",
      "0.005855902425213718 \t 1.1904320523450544\n",
      "0.6313304144100189 \t 1.0266297119232393\n",
      "0.028571519353103283 \t 1.058390509530385\n",
      "0.7736990145462134 \t 1.1281077234847359\n",
      "0.9592417769461468 \t 1.0881901039942394\n",
      "0.9666467935121079 \t 1.0625452116990524\n",
      "0.09967980136754176 \t 1.0732820143748836\n",
      "0.2988732320199949 \t 1.089220478652022\n",
      "************* 5 번차 epoch *************\n",
      "1.2970672789506312 \t 0.9851142642633629\n",
      "2.7076517220467076 \t 1.0191113453178078\n",
      "1.717503632530371 \t 1.087307383775543\n",
      "0.010732995953743702 \t 1.0378584654284653\n",
      "1.6223219864319038 \t 1.0421192313849712\n",
      "0.5983523605544286 \t 1.065711986739089\n",
      "3.6770946589955216 \t 1.0324987049167218\n",
      "0.33578699660860856 \t 1.0421534083773323\n",
      "************* 6 번차 epoch *************\n",
      "6.909672664214158 \t 0.8316459336743003\n",
      "0.5412937920271447 \t 1.05225022819261\n",
      "0.5173767348668407 \t 1.1173748773576082\n",
      "0.0002536472321091479 \t 1.0959336552532999\n",
      "1.8347061443168793 \t 1.1050255320125593\n",
      "3.87957701964076 \t 1.0858449927874199\n",
      "0.034224039279673796 \t 1.0723378156344174\n",
      "0.5928050379944414 \t 1.0593258021915246\n",
      "************* 7 번차 epoch *************\n",
      "0.014904020820778761 \t 1.1063262703667847\n",
      "0.3581391562422032 \t 0.9998012040569987\n",
      "0.1777792795674968 \t 0.9957458584682551\n",
      "0.2077783303675124 \t 1.0417120247706273\n",
      "0.3168592612346007 \t 1.0307674242730098\n",
      "0.0361508562333817 \t 1.0363118623479752\n",
      "0.24060471234138503 \t 1.0575592995116372\n",
      "0.1839052657522956 \t 1.0608036819201931\n",
      "************* 8 번차 epoch *************\n",
      "2.1505301563406767 \t 1.0796600967913843\n",
      "2.09470552864408 \t 1.0199990349155703\n",
      "0.2712228218018281 \t 0.9605446617311653\n",
      "0.5925299002786257 \t 0.9816056771093584\n",
      "0.5435467646906523 \t 1.0088513421930763\n",
      "2.1459373604915655 \t 1.0086904310429712\n",
      "1.6458932371590396 \t 1.0426309799908484\n",
      "0.49647736816599747 \t 1.0545045507861237\n",
      "************* 9 번차 epoch *************\n",
      "5.344504458747484 \t 1.1582022538702539\n",
      "0.01742548890055465 \t 1.148891099924984\n",
      "0.04678600443157652 \t 1.116752101914507\n",
      "1.1082862783342837 \t 1.101475299146872\n",
      "0.2776646289912061 \t 1.0662041517541165\n",
      "2.3634019094517216 \t 1.064131618079745\n",
      "0.11834415824898463 \t 1.0471553805647433\n",
      "0.6762219969742803 \t 1.0516599204945287\n",
      "************* 10 번차 epoch *************\n",
      "0.4040619905952021 \t 1.042472679702191\n",
      "0.9478599160794423 \t 1.0824517166975298\n",
      "0.0522411440666936 \t 1.1354122526668762\n",
      "0.5293332842029357 \t 1.0890365671225548\n",
      "0.7632306776086274 \t 1.062947501130576\n",
      "0.008046881907461058 \t 1.032708592156764\n",
      "2.050879915655512 \t 1.0123867437230976\n",
      "2.0419027555518494 \t 1.046066932223565\n"
     ]
    }
   ],
   "source": [
    "for j in range(1,10+1):\n",
    "    print('*************',j,'번차 epoch *************')\n",
    "    data=np.random.permutation(data)\n",
    "    X_batch= data[:,0]\n",
    "    y_batch= data[:,1]\n",
    "    X_batch=np.reshape(X_batch,(idx,size))\n",
    "    y_batch=np.reshape(y_batch,(idx,size))\n",
    "\n",
    "    number_minibatch= np.int(np.ceil(X_batch.shape[0]/minibatch_size))\n",
    "    \n",
    "    avglo=0\n",
    "    for i in range(1,number_minibatch+1):\n",
    "        X_batch_temp=X_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "        y_temp=y_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "        loss=model.forward(X_batch_temp,y_temp)\n",
    "        avglo+=loss\n",
    "        if i % 100 ==0:\n",
    "            print(loss,'\\t',avglo/(i))\n",
    "            #avglo=0\n",
    "        model.backward(X_batch_temp,y_temp)\n",
    "        # print(model.w_grad)\n",
    "        # print(model.b_grad)\n",
    "    #     print(model.W)\n",
    "    #     print(model.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(data,idx,minibatch_size, epoch_size):\n",
    "    global W\n",
    "    global b\n",
    "    dat_list=[]\n",
    "#     X_batch= data[:,0]\n",
    "#     y_batch= data[:,1]\n",
    "#     X_batch=np.reshape(X_batch,(idx,size))\n",
    "#     y_batch=np.reshape(y_batch,(idx,size))\n",
    "\n",
    "    number_minibatch= np.int(np.ceil(data.shape[0]/minibatch_size))\n",
    "#     W=np.random.uniform(-R,R,size=size)\n",
    "#     b=np.random.uniform(-R,R,size=1)\n",
    "    \n",
    "    for j in range(1,epoch_size+1):\n",
    "        print('*************',j,'번차 epoch *************')\n",
    "        data=np.random.permutation(data)\n",
    "        X_batch= data[:,0]\n",
    "        y_batch= data[:,1]\n",
    "        X_batch=np.reshape(X_batch,(idx,size))\n",
    "        y_batch=np.reshape(y_batch,(idx,size))\n",
    "        \n",
    "        number_minibatch= np.int(np.ceil(X_batch.shape[0]/minibatch_size))\n",
    "    \n",
    "    #    assert X_batch.shape[0] == y_batch.shape[0]\n",
    "    #    assert X_batch.shape[1] == weights['W'].shape[0]\n",
    "        \n",
    "        for i in range(1, number_minibatch+1):\n",
    "            X_batch_temp=X_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "            y_temp=y_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "            \n",
    "            N=W*X_batch_temp\n",
    "            f= N+b\n",
    "            loss=np.mean(np.power(y_temp-f,2))\n",
    "            if i==1:\n",
    "                print('loss',loss)\n",
    "            forward_info['X']= X_batch_temp\n",
    "            forward_info['N']= N       # \n",
    "            forward_info['f']= f       # 예측값\n",
    "            forward_info['y']= y_temp # 실제값\n",
    "\n",
    "            # 전체코드로 본 도함수 계산과정\n",
    "            batch_size=forward_info['X'].shape[0]\n",
    "            dJdf=-2*(forward_info['y']-forward_info['f'])\n",
    "            dfdN=np.ones_like(forward_info['N']) \n",
    "            dfdB=np.ones_like(forward_info['N'])\n",
    "            dJdN=dJdf*dfdN \n",
    "            dNdW=np.transpose(forward_info['X'],(1,0))\n",
    "\n",
    "            dJdW=np.dot(dNdW, dJdN)\n",
    "            dLdB=(dJdf*dfdB).sum(axis=0)\n",
    "\n",
    "            loss_grad['W']=dJdW\n",
    "            loss_grad['B']=dLdB\n",
    "\n",
    "#             for key in weights.keys():\n",
    "#                 weights[key]=weights[key]- 0.00001 * loss_grad[key]\n",
    "            W=W - 0.00001 * loss_grad['W']\n",
    "            b=b - 0.00001 * loss_grad['B']\n",
    "        N=W*X_batch\n",
    "        f= N+b\n",
    "        loss=np.mean(np.power(y_batch-f,2))\n",
    "        print('Loss',loss)\n",
    "      \n",
    "        print('=================================')\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_data\n",
      "************* 1 번차 epoch *************\n",
      "loss 1.0233416278338576\n",
      "Loss 0.9882879332784041\n",
      "=================================\n",
      "************* 2 번차 epoch *************\n",
      "loss 1.5451502438276683\n",
      "Loss 0.9873357327667032\n",
      "=================================\n",
      "************* 3 번차 epoch *************\n",
      "loss 1.418639155198556\n",
      "Loss 0.9869866452882351\n",
      "=================================\n",
      "************* 4 번차 epoch *************\n",
      "loss 1.1491791136524265\n",
      "Loss 0.986984066069048\n",
      "=================================\n",
      "************* 5 번차 epoch *************\n",
      "loss 0.39157975952536495\n",
      "Loss 0.9869806865020484\n",
      "=================================\n",
      "************* 6 번차 epoch *************\n",
      "loss 0.8882260005107062\n",
      "Loss 0.9869509127034225\n",
      "=================================\n",
      "************* 7 번차 epoch *************\n",
      "loss 0.5494115320689925\n",
      "Loss 0.986959271268826\n",
      "=================================\n",
      "************* 8 번차 epoch *************\n",
      "loss 0.5201336393579441\n",
      "Loss 0.9869582606689452\n",
      "=================================\n",
      "************* 9 번차 epoch *************\n",
      "loss 1.06729614104604\n",
      "Loss 0.9869490022939055\n",
      "=================================\n",
      "************* 10 번차 epoch *************\n",
      "loss 1.2747636681136876\n",
      "Loss 0.986950402453556\n",
      "=================================\n",
      "************* 11 번차 epoch *************\n",
      "loss 1.4151873240730999\n",
      "Loss 0.9869489906361721\n",
      "=================================\n",
      "************* 12 번차 epoch *************\n",
      "loss 0.7773293651625085\n",
      "Loss 0.9869712813688362\n",
      "=================================\n",
      "************* 13 번차 epoch *************\n",
      "loss 1.4078949169286985\n",
      "Loss 0.9869668651808309\n",
      "=================================\n",
      "************* 14 번차 epoch *************\n",
      "loss 0.9355287075770067\n",
      "Loss 0.9869511500137998\n",
      "=================================\n",
      "************* 15 번차 epoch *************\n",
      "loss 0.8383998661829594\n",
      "Loss 0.9869521788447478\n",
      "=================================\n",
      "************* 16 번차 epoch *************\n",
      "loss 0.6793898891178433\n",
      "Loss 0.9869625231069842\n",
      "=================================\n",
      "************* 17 번차 epoch *************\n",
      "loss 0.5537574836087571\n",
      "Loss 0.986960779482302\n",
      "=================================\n",
      "************* 18 번차 epoch *************\n",
      "loss 1.1000241992300517\n",
      "Loss 0.9869502863672663\n",
      "=================================\n",
      "************* 19 번차 epoch *************\n",
      "loss 1.3743986167917894\n",
      "Loss 0.9869488496207703\n",
      "=================================\n",
      "************* 20 번차 epoch *************\n",
      "loss 0.7251725208467452\n",
      "Loss 0.9869624811441913\n",
      "=================================\n",
      "************* 21 번차 epoch *************\n",
      "loss 0.7246761344449031\n",
      "Loss 0.9869603196756995\n",
      "=================================\n",
      "************* 22 번차 epoch *************\n",
      "loss 0.9512473189957232\n",
      "Loss 0.9869486576838774\n",
      "=================================\n",
      "************* 23 번차 epoch *************\n",
      "loss 0.6955392705655575\n",
      "Loss 0.9869500642997938\n",
      "=================================\n",
      "************* 24 번차 epoch *************\n",
      "loss 0.7866476053328986\n",
      "Loss 0.9869625544422395\n",
      "=================================\n",
      "************* 25 번차 epoch *************\n",
      "loss 1.4281726090602729\n",
      "Loss 0.9870236613991225\n",
      "=================================\n",
      "************* 26 번차 epoch *************\n",
      "loss 1.089983463199358\n",
      "Loss 0.986982503238064\n",
      "=================================\n",
      "************* 27 번차 epoch *************\n",
      "loss 1.2599028528969556\n",
      "Loss 0.9869521372162547\n",
      "=================================\n",
      "************* 28 번차 epoch *************\n",
      "loss 0.8998144567238342\n",
      "Loss 0.9869509954618169\n",
      "=================================\n",
      "************* 29 번차 epoch *************\n",
      "loss 0.9183320579402461\n",
      "Loss 0.9869487430766197\n",
      "=================================\n",
      "************* 30 번차 epoch *************\n",
      "loss 0.5193049359680303\n",
      "Loss 0.9869531576885116\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "print('Train_data')\n",
    "linear_regression(train_data_set,train_idx,20,30)\n",
    "\n",
    "# print('\\ndev_data')\n",
    "# linear_regression(dev_data_set,dev_idx,20,30)\n",
    "\n",
    "# print('\\nTest_data')\n",
    "# linear_regression(test_data_set,test_idx,20,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
