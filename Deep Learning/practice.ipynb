{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 6]\n",
      "[[1 0 0]\n",
      " [0 4 0]\n",
      " [0 0 6]]\n",
      "11\n",
      "[[ 1  4 49]\n",
      " [ 9 16 64]\n",
      " [25 81 36]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "a=[[1,2,7],[3,4,8],[5,9,6]]\n",
    "a=np.array(a)\n",
    "c=np.transpose(a)\n",
    "b=np.diag(a)\n",
    "e=np.diag(np.diag(a))\n",
    "print(b)\n",
    "print(e)\n",
    "d=np.trace(e)\n",
    "print(d)\n",
    "\n",
    "g=np.power(a,2)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4, 49],\n",
       "       [ 9, 16, 64],\n",
       "       [25, 81, 36]], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square(x):\n",
    "    return np.power(x,2)\n",
    "square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_deriv(chain, input_range):\n",
    "    \n",
    "    assert len(chain)==2\n",
    "    f1=Chain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "a=13\n",
    "for i in range(1,a+1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [5],\n",
       "       [6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.arange(3).reshape(3,1)\n",
    "print(a)\n",
    "a+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 241.66666666666666\n",
      "\n",
      " {'X': array([[1, 2, 7],\n",
      "       [3, 4, 8],\n",
      "       [5, 9, 6]]), 'N': array([[10],\n",
      "       [15],\n",
      "       [20]]), 'f': array([[11],\n",
      "       [16],\n",
      "       [21]]), 'y': array([[1],\n",
      "       [1],\n",
      "       [1]])}\n",
      "B: [[1]]\n",
      "1 W\n",
      "2 B\n"
     ]
    }
   ],
   "source": [
    "# 2.3.4 코드로 살펴보는 선형회귀linear regression\n",
    "\n",
    "matrix= [[1,2,7],[3,4,8],[5,9,6]]\n",
    "matrix=np.array(matrix)\n",
    "y = [[1],[1],[1]]\n",
    "y=np.array(y)\n",
    "w = [[1],[1],[1]]\n",
    "w=np.array(w)\n",
    "\n",
    "B = np.random.randint(1,2,(1,1))\n",
    "\n",
    "weights = {'W':w,'B':B} \n",
    "\n",
    "def forward_linear_Regression(X_batch, y_batch, weights):\n",
    "    assert X_batch.shape[0] == y_batch.shape[0]\n",
    "    assert X_batch.shape[1] == weights['W'].shape[0]\n",
    "    assert weights['B'].shape[0] == weights['B'].shape[1]==1\n",
    "    \n",
    "    N=np.dot(X_batch,weights['W'])\n",
    "    f= N+weights['B']\n",
    "    loss=np.mean(np.power(y_batch-f,2))\n",
    "    \n",
    "    #순방향으로 갈때 중간값을 저장해가면서 진행\n",
    "    forward_info={}\n",
    "    forward_info['X']= X_batch\n",
    "    forward_info['N']= N\n",
    "    forward_info['f']= f\n",
    "    forward_info['y']= y_batch\n",
    "    \n",
    "    return print('loss', loss), print('\\n', forward_info)\n",
    "    \n",
    "\n",
    "forward_linear_Regression(matrix,y,weights)\n",
    "\n",
    "print('B:',B)\n",
    "\n",
    "o=1\n",
    "for key in weights.keys():\n",
    "    print(o,key)\n",
    "    o=o+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N \n",
      " [[10]\n",
      " [15]\n",
      " [20]]\n",
      "f \n",
      " [[11]\n",
      " [16]\n",
      " [21]]\n",
      "725\n",
      "\n",
      " dJdf\n",
      "[[20]\n",
      " [30]\n",
      " [40]]\n",
      "\n",
      " dfdN\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      " dNdW\n",
      "[[1 3 5]\n",
      " [2 4 9]\n",
      " [7 8 6]]\n",
      "\n",
      " dJdN=dJdf*dfdN\n",
      "[[20]\n",
      " [30]\n",
      " [40]]\n",
      "==================================================================\n",
      "batch gradient descent\n",
      "\n",
      "\n",
      "1 회 반복\n",
      "before\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "after\n",
      "[[0.69]\n",
      " [0.48]\n",
      " [0.38]]\n",
      "before\n",
      "[[1]]\n",
      "after\n",
      "[[0.91]]\n",
      "\n",
      "\n",
      "2 회 반복\n",
      "before\n",
      "[[0.69]\n",
      " [0.48]\n",
      " [0.38]]\n",
      "after\n",
      "[[ 0.38]\n",
      " [-0.04]\n",
      " [-0.24]]\n",
      "before\n",
      "[[0.91]]\n",
      "after\n",
      "[[0.82]]\n",
      "\n",
      "\n",
      "3 회 반복\n",
      "before\n",
      "[[ 0.38]\n",
      " [-0.04]\n",
      " [-0.24]]\n",
      "after\n",
      "[[ 0.07]\n",
      " [-0.56]\n",
      " [-0.86]]\n",
      "before\n",
      "[[0.82]]\n",
      "after\n",
      "[[0.73]]\n"
     ]
    }
   ],
   "source": [
    "# 2.4.3 전체코드로 본 도함수 계산과정\n",
    "\n",
    "matrix= [[1,2,7],[3,4,8],[5,9,6]]\n",
    "matrix=np.array(matrix)\n",
    "y = [[1],[1],[1]]\n",
    "y=np.array(y)\n",
    "w = [[1],[1],[1]]\n",
    "w=np.array(w)\n",
    "B = np.random.randint(1,2,(1,1))\n",
    "weights = {'W':w,'B':B} \n",
    "\n",
    "loss_grad={}    # dJdW, dJdB 저장공간\n",
    "forward_info={} # 순방향 저장공간\n",
    "\n",
    "\n",
    "def loss_gradient(X_batch, y_batch, weights):\n",
    "    assert X_batch.shape[0] == y_batch.shape[0]\n",
    "    assert X_batch.shape[1] == weights['W'].shape[0]\n",
    "    assert weights['B'].shape[0] == weights['B'].shape[1]==1\n",
    "    \n",
    "    N=np.dot(X_batch,weights['W'])\n",
    "    f= N+weights['B']\n",
    "    loss=np.sum(np.power(y_batch-f,2))\n",
    "    \n",
    "    print('N \\n',N)\n",
    "    print('f \\n',f)\n",
    "    print(loss)\n",
    "    \n",
    "    #순방향으로 갈때 중간값을 저장해가면서 진행\n",
    "    forward_info['X']= X_batch\n",
    "    forward_info['N']= N       # \n",
    "    forward_info['f']= f       # 예측값\n",
    "    forward_info['y']= y_batch # 실제값\n",
    "\n",
    "    # 2.4.3 전체코드로 본 도함수 계산과정\n",
    "\n",
    "    batch_size=forward_info['X'].shape[0]\n",
    "    dJdf=-2*(forward_info['y']-forward_info['f'])\n",
    "    '''a(N,B)=N+B. N의 어떤 요소를 1단위 증가시키면 f의 값 역시 1단위 증가 따라서  \n",
    "    dfdN의 모든 요소값이 1인 행렬이 되는 것'''  \n",
    "    dfdN=np.ones_like(forward_info['N']) \n",
    "    dfdB=np.ones_like(forward_info['N'])\n",
    "    dJdN=dJdf*dfdN \n",
    "    '''# ??=>이건 왜 구하는 거임? 48번째줄을 구할때 dot으로 여태까지 계산을 위해서인가...\n",
    "    \n",
    "       3X1 과 3X1을 어떻게 곱해지는지 이해가 안됐지만 그 이유가 '*'와 'np.dot'의 차이를 알아야한다.\n",
    "       어짜피 연쇄법칙으로 쭉 곱해가면서 가야하는데 위의 식을 곱하기 위해선 무조건 행렬이라고\n",
    "       dot의 개념을 곱하면 안되고 똑같이 곱하되 numpy.array의 성질을 이용(같은 열과 같은 행이면\n",
    "       위와 같이 곱해됨)한다.\n",
    "       그래서 위에서는 '*'을 이용했지만 밑에서는 np.dot을 이용한다(즉, 곱해야 하는 행렬의 꼴을 봐가면서 \n",
    "       '*' 혹은 'np.dot'을 이용하면 된다고 판단. 허나 만약 이도저도 안된다면....이 아니라 만약 그렇다면\n",
    "       아마 이 계산과정 자체가 나오지 않았을 것) '''\n",
    "    dNdW=np.transpose(forward_info['X'],(1,0))\n",
    "    \n",
    "    \n",
    "    print('\\n dJdf')\n",
    "    print(dJdf)\n",
    "    \n",
    "    print('\\n dfdN')\n",
    "    print(dfdN)\n",
    "    \n",
    "    print('\\n dNdW')\n",
    "    print(dNdW)\n",
    "    \n",
    "    print('\\n dJdN=dJdf*dfdN')\n",
    "    print(dJdN)\n",
    "    \n",
    "    dJdW=np.dot(dNdW, dJdN)\n",
    "    dLdB=(dJdf*dfdB).sum(axis=0)\n",
    "\n",
    "    \n",
    "    loss_grad['W']=dJdW\n",
    "    loss_grad['B']=dLdB\n",
    "\n",
    "            \n",
    "    return \n",
    "\n",
    "loss_gradient(matrix,y,weights)\n",
    "\n",
    "print('==================================================================')\n",
    "\n",
    "print('batch gradient descent')\n",
    "\n",
    "def batch(loss_grad):\n",
    "    for i in range(1,4):\n",
    "        print('\\n')\n",
    "        print(i,'회 반복')\n",
    "        for key in weights.keys():\n",
    "            print('before')\n",
    "            print(weights[key])\n",
    "            weights[key] = weights[key]- 0.001 * loss_grad[key]\n",
    "            print('after')\n",
    "            print(weights[key])\n",
    "batch(loss_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4.3 초기버전(절대 지우지 말것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "batch gradient descent\n",
      "******* 1 번차 epoch*******\n",
      "\n",
      " 0 ~ 2 열\n",
      "N \n",
      " [[6]\n",
      " [7]\n",
      " [8]]\n",
      "f \n",
      " [[7]\n",
      " [8]\n",
      " [9]]\n",
      "Loss: 149\n",
      "{'W': array([[ 88],\n",
      "       [ 84],\n",
      "       [126]]), 'B': array([42])}\n",
      "W\n",
      "before\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "after\n",
      "[[0.9912]\n",
      " [0.9916]\n",
      " [0.9874]]\n",
      "\n",
      "\n",
      "B\n",
      "before\n",
      "[[1]]\n",
      "after\n",
      "[[0.9958]]\n",
      "\n",
      "\n",
      "\n",
      " 3 ~ 5 열\n",
      "N \n",
      " [[ 8.9102]\n",
      " [ 9.9014]\n",
      " [10.8926]]\n",
      "f \n",
      " [[ 9.906 ]\n",
      " [10.8972]\n",
      " [11.8884]]\n",
      "Loss: 295.8286584\n",
      "{'W': array([[300.8808],\n",
      "       [118.7664],\n",
      "       [178.1496]]), 'B': array([59.3832])}\n",
      "W\n",
      "before\n",
      "[[0.9912]\n",
      " [0.9916]\n",
      " [0.9874]]\n",
      "after\n",
      "[[0.96111192]\n",
      " [0.97972336]\n",
      " [0.96958504]]\n",
      "\n",
      "\n",
      "B\n",
      "before\n",
      "[[0.9958]]\n",
      "after\n",
      "[[0.98986168]]\n",
      "\n",
      "\n",
      "\n",
      " 6 ~ 8 열\n",
      "N \n",
      " [[11.59598528]\n",
      " [12.5570972 ]\n",
      " [13.51820912]]\n",
      "f \n",
      " [[12.58584696]\n",
      " [13.54695888]\n",
      " [14.5080708 ]]\n",
      "Loss: 474.1260036547649\n",
      "{'W': array([[606.09847392],\n",
      "       [150.56350656],\n",
      "       [225.84525984]]), 'B': array([75.28175328])}\n",
      "W\n",
      "before\n",
      "[[0.96111192]\n",
      " [0.97972336]\n",
      " [0.96958504]]\n",
      "after\n",
      "[[0.90050207]\n",
      " [0.96466701]\n",
      " [0.94700051]]\n",
      "\n",
      "\n",
      "B\n",
      "before\n",
      "[[0.98986168]]\n",
      "after\n",
      "[[0.9823335]]\n",
      "\n",
      "\n",
      "******* 2 번차 epoch*******\n",
      "\n",
      " 0 ~ 2 열\n",
      "N \n",
      " [[5.67083763]\n",
      " [6.57133971]\n",
      " [7.47184178]]\n",
      "f \n",
      " [[6.65317114]\n",
      " [7.55367321]\n",
      " [8.45417528]]\n",
      "Loss: 130.47370562049468\n",
      "{'W': array([[ 82.24608682],\n",
      "       [ 78.64407853],\n",
      "       [117.96611779]]), 'B': array([39.32203926])}\n",
      "W\n",
      "before\n",
      "[[0.90050207]\n",
      " [0.96466701]\n",
      " [0.94700051]]\n",
      "after\n",
      "[[0.89227746]\n",
      " [0.9568026 ]\n",
      " [0.9352039 ]]\n",
      "\n",
      "\n",
      "B\n",
      "before\n",
      "[[0.9823335]]\n",
      "after\n",
      "[[0.9784013]]\n",
      "\n",
      "\n",
      "\n",
      " 3 ~ 5 열\n",
      "N \n",
      " [[ 8.28832677]\n",
      " [ 9.18060423]\n",
      " [10.07288169]]\n",
      "f \n",
      " [[ 9.26672807]\n",
      " [10.15900553]\n",
      " [11.05128299]]\n",
      "Loss: 253.25446504480863\n",
      "{'W': array([[278.33927576],\n",
      "       [109.90806636],\n",
      "       [164.86209954]]), 'B': array([54.95403318])}\n",
      "W\n",
      "before\n",
      "[[0.89227746]\n",
      " [0.9568026 ]\n",
      " [0.9352039 ]]\n",
      "after\n",
      "[[0.86444354]\n",
      " [0.94581179]\n",
      " [0.91871769]]\n",
      "\n",
      "\n",
      "B\n",
      "before\n",
      "[[0.9784013]]\n",
      "after\n",
      "[[0.9729059]]\n",
      "\n",
      "\n",
      "\n",
      " 6 ~ 8 열\n",
      "N \n",
      " [[10.69888142]\n",
      " [11.56332496]\n",
      " [12.42776849]]\n",
      "f \n",
      " [[11.67178732]\n",
      " [12.53623085]\n",
      " [13.40067439]]\n",
      "Loss: 400.74839226007464\n",
      "{'W': array([[557.19685518],\n",
      "       [138.43477026],\n",
      "       [207.65215539]]), 'B': array([69.21738513])}\n",
      "W\n",
      "before\n",
      "[[0.86444354]\n",
      " [0.94581179]\n",
      " [0.91871769]]\n",
      "after\n",
      "[[0.80872385]\n",
      " [0.93196832]\n",
      " [0.89795248]]\n",
      "\n",
      "\n",
      "B\n",
      "before\n",
      "[[0.9729059]]\n",
      "after\n",
      "[[0.96598416]]\n",
      "\n",
      "\n",
      "******* 3 번차 epoch*******\n",
      "\n",
      " 0 ~ 2 열\n",
      "N \n",
      " [[5.36651792]\n",
      " [6.17524177]\n",
      " [6.98396562]]\n",
      "f \n",
      " [[6.33250208]\n",
      " [7.14122593]\n",
      " [7.94994978]]\n",
      "Loss: 114.45203617371786\n",
      "{'W': array([[ 76.92960652],\n",
      "       [ 73.69471112],\n",
      "       [110.54206668]]), 'B': array([36.84735556])}\n",
      "W\n",
      "before\n",
      "[[0.80872385]\n",
      " [0.93196832]\n",
      " [0.89795248]]\n",
      "after\n",
      "[[0.80103089]\n",
      " [0.92459885]\n",
      " [0.88689827]]\n",
      "\n",
      "\n",
      "B\n",
      "before\n",
      "[[0.96598416]]\n",
      "after\n",
      "[[0.96229942]]\n",
      "\n",
      "\n",
      "\n",
      " 3 ~ 5 열\n",
      "N \n",
      " [[7.71401606]\n",
      " [8.51504695]\n",
      " [9.31607784]]\n",
      "f \n",
      " [[ 8.67631549]\n",
      " [ 9.47734638]\n",
      " [10.27837727]]\n",
      "Loss: 216.87950580813276\n",
      "{'W': array([[257.5245149 ],\n",
      "       [101.72815654],\n",
      "       [152.5922348 ]]), 'B': array([50.86407827])}\n",
      "W\n",
      "before\n",
      "[[0.80103089]\n",
      " [0.92459885]\n",
      " [0.88689827]]\n",
      "after\n",
      "[[0.77527844]\n",
      " [0.91442603]\n",
      " [0.87163905]]\n",
      "\n",
      "\n",
      "B\n",
      "before\n",
      "[[0.96229942]]\n",
      "after\n",
      "[[0.95721302]]\n",
      "\n",
      "\n",
      "\n",
      " 6 ~ 8 열\n",
      "N \n",
      " [[ 9.87071827]\n",
      " [10.64599671]\n",
      " [11.42127515]]\n",
      "f \n",
      " [[10.82793129]\n",
      " [11.60320973]\n",
      " [12.37848817]]\n",
      "Loss: 338.4862828577476\n",
      "{'W': array([[512.05518065],\n",
      "       [127.23851672],\n",
      "       [190.85777509]]), 'B': array([63.61925836])}\n",
      "W\n",
      "before\n",
      "[[0.77527844]\n",
      " [0.91442603]\n",
      " [0.87163905]]\n",
      "after\n",
      "[[0.72407292]\n",
      " [0.90170218]\n",
      " [0.85255327]]\n",
      "\n",
      "\n",
      "B\n",
      "before\n",
      "[[0.95721302]]\n",
      "after\n",
      "[[0.95085109]]\n",
      "\n",
      "\n",
      "******* 4 번차 epoch*******\n",
      "\n",
      " 0 ~ 2 열\n",
      "N \n",
      " [[5.08513709]\n",
      " [5.80921001]\n",
      " [6.53328293]]\n",
      "f \n",
      " [[6.03598818]\n",
      " [6.7600611 ]\n",
      " [7.48413402]]\n",
      "Loss: 100.58347471209066\n",
      "{'W': array([[ 72.01702485],\n",
      "       [ 69.12073316],\n",
      "       [103.68109975]]), 'B': array([34.56036658])}\n",
      "W\n",
      "before\n",
      "[[0.72407292]\n",
      " [0.90170218]\n",
      " [0.85255327]]\n",
      "after\n",
      "[[0.71687122]\n",
      " [0.89479011]\n",
      " [0.84218516]]\n",
      "\n",
      "\n",
      "B\n",
      "before\n",
      "[[0.95085109]]\n",
      "after\n",
      "[[0.94739505]]\n",
      "\n",
      "\n",
      "\n",
      " 3 ~ 5 열\n",
      "N \n",
      " [[7.18362056]\n",
      " [7.90049178]\n",
      " [8.617363  ]]\n",
      "f \n",
      " [[8.13101562]\n",
      " [8.84788683]\n",
      " [9.56475805]]\n",
      "Loss: 185.7957919285563\n",
      "{'W': array([[238.30408987],\n",
      "       [ 94.174642  ],\n",
      "       [141.261963  ]]), 'B': array([47.087321])}\n",
      "W\n",
      "before\n",
      "[[0.71687122]\n",
      " [0.89479011]\n",
      " [0.84218516]]\n",
      "after\n",
      "[[0.69304081]\n",
      " [0.88537264]\n",
      " [0.82805896]]\n",
      "\n",
      "\n",
      "B\n",
      "before\n",
      "[[0.94739505]]\n",
      "after\n",
      "[[0.94268632]]\n",
      "\n",
      "\n",
      "\n",
      " 6 ~ 8 열\n",
      "N \n",
      " [[ 9.10620784]\n",
      " [ 9.79924865]\n",
      " [10.49228945]]\n",
      "f \n",
      " [[10.04889416]\n",
      " [10.74193497]\n",
      " [11.43497578]]\n",
      "Loss: 285.6765017928727\n",
      "{'W': array([[470.38504162],\n",
      "       [116.9032196 ],\n",
      "       [175.35482939]]), 'B': array([58.4516098])}\n",
      "W\n",
      "before\n",
      "[[0.69304081]\n",
      " [0.88537264]\n",
      " [0.82805896]]\n",
      "after\n",
      "[[0.6460023 ]\n",
      " [0.87368232]\n",
      " [0.81052348]]\n",
      "\n",
      "\n",
      "B\n",
      "before\n",
      "[[0.94268632]]\n",
      "after\n",
      "[[0.93684116]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.4.3 초기버전(절대 지우지 말것)\n",
    "matrix= [[1,2,3],[2,2,3],[3,2,3],[4,2,3],[5,2,3],[6,2,3],[7,2,3],[8,2,3],[9,2,3]]\n",
    "matrix=np.array(matrix)\n",
    "y = [[1],[1],[1],[1],[1],[1],[1],[1],[1]]\n",
    "y=np.array(y)\n",
    "w = [[1],[1],[1]]\n",
    "w=np.array(w)\n",
    "B = np.random.randint(1,2,(1,1))\n",
    "weights = {'W':w,'B':B} \n",
    "\n",
    "loss_grad={}    # dJdW, dJdB 저장공간\n",
    "forward_info={} # 순방향 저장공간\n",
    "\n",
    "\n",
    "def loss_gradient(X_batch, y_batch, weights):\n",
    "    assert X_batch.shape[0] == y_batch.shape[0]\n",
    "    assert X_batch.shape[1] == weights['W'].shape[0]\n",
    "    assert weights['B'].shape[0] == weights['B'].shape[1]==1\n",
    "    \n",
    "    N=np.dot(X_batch,weights['W'])\n",
    "    f= N+weights['B']\n",
    "    loss=np.sum(np.power(y_batch-f,2))\n",
    "    \n",
    "    print('N \\n',N)\n",
    "    print('f \\n',f)\n",
    "    print('Loss:',loss)\n",
    "    \n",
    "    #순방향으로 갈때 중간값을 저장해가면서 진행\n",
    "    forward_info['X']= X_batch\n",
    "    forward_info['N']= N       # \n",
    "    forward_info['f']= f       # 예측값\n",
    "    forward_info['y']= y_batch # 실제값\n",
    "\n",
    "    # 전체코드로 본 도함수 계산과정\n",
    "\n",
    "    batch_size=forward_info['X'].shape[0]\n",
    "    dJdf=-2*(forward_info['y']-forward_info['f'])\n",
    "    '''a(N,B)=N+B. N의 어떤 요소를 1단위 증가시키면 f의 값 역시 1단위 증가 따라서  \n",
    "    dfdN의 모든 요소값이 1인 행렬이 되는 것'''  \n",
    "    dfdN=np.ones_like(forward_info['N']) \n",
    "    dfdB=np.ones_like(forward_info['N'])\n",
    "    dJdN=dJdf*dfdN \n",
    "    '''# ??=>이건 왜 구하는 거임? 48번째줄을 구할때 dot으로 여태까지 계산을 위해서인가...\n",
    "    \n",
    "       3X1 과 3X1을 어떻게 곱해지는지 이해가 안됐지만 그 이유가 '*'와 'np.dot'의 차이를 알아야한다.\n",
    "       어짜피 연쇄법칙으로 쭉 곱해가면서 가야하는데 위의 식을 곱하기 위해선 무조건 행렬이라고\n",
    "       dot의 개념을 곱하면 안되고 똑같이 곱하되 numpy.array의 성질을 이용(같은 열과 같은 행이면\n",
    "       위와 같이 곱해됨)한다.\n",
    "       그래서 위에서는 '*'을 이용했지만 밑에서는 np.dot을 이용한다(즉, 곱해야 하는 행렬의 꼴을 봐가면서 \n",
    "       '*' 혹은 'np.dot'을 이용하면 된다고 판단. 허나 만약 이도저도 안된다면....이 아니라 만약 그렇다면\n",
    "       아마 이 계산과정 자체가 나오지 않았을 것) '''\n",
    "    dNdW=np.transpose(forward_info['X'],(1,0))\n",
    "    \n",
    "    \n",
    "    dJdW=np.dot(dNdW, dJdN)\n",
    "    dLdB=(dJdf*dfdB).sum(axis=0)\n",
    "\n",
    "    \n",
    "    loss_grad['W']=dJdW\n",
    "    loss_grad['B']=dLdB\n",
    "\n",
    "            \n",
    "    return print(loss_grad)\n",
    "\n",
    "#loss_gradient(matrix,y,weights)\n",
    "\n",
    "print('==================================================================')\n",
    "\n",
    "print('batch gradient descent')\n",
    "def batch(loss_grad):\n",
    "    for i in range(1,4):\n",
    "        print('\\n')\n",
    "        print(i,'회 반복')\n",
    "        for key in weights.keys():\n",
    "            print('before')\n",
    "            print(weights[key])\n",
    "            weights[key] = weights[key]- 0.001 * loss_grad[key]\n",
    "            print('after')\n",
    "            print(weights[key])\n",
    "#batch(loss_grad)\n",
    "\n",
    "minibatch_size = 3\n",
    "number_minibatch= np.int(np.ceil(matrix.shape[0]/minibatch_size))\n",
    "epoch_size=4\n",
    "\n",
    "for j in range(1,epoch_size+1):\n",
    "    print('*******',j,'번차 epoch*******')\n",
    "    for i in range(1, number_minibatch+1):\n",
    "        print('\\n',minibatch_size*i-(minibatch_size-1)-1,'~',minibatch_size*i-1,'열')\n",
    "        matrix1=matrix[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "        y1=y[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "        loss_gradient(matrix1,y1,weights)\n",
    "\n",
    "        for key in weights.keys():\n",
    "            print(key)\n",
    "            print('before')\n",
    "            print(weights[key])\n",
    "            weights[key]=weights[key]- 0.0001 * loss_grad[key]\n",
    "            print('after')\n",
    "            print(weights[key])\n",
    "            print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.10241523  9.68028903  7.72958862  3.74758091  1.1918811  -2.42086939\n",
      "  5.46478285  3.55489455  5.23766107  3.18929798]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2., 0., 1., 0., 2., 1., 2., 0., 1., 1.]),\n",
       " array([-2.42086939e+00, -1.21075354e+00, -6.37702934e-04,  1.20947814e+00,\n",
       "         2.41959398e+00,  3.62970982e+00,  4.83982566e+00,  6.04994150e+00,\n",
       "         7.26005734e+00,  8.47017319e+00,  9.68028903e+00]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b=np.random.uniform(-10,10,size=10)\n",
    "print(b)\n",
    "plt.hist(b,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "W= np.random.uniform(-10,10,size=1000)\n",
    "b= np.random.uniform(-10,10,size=1000)\n",
    "x= np.random.uniform(-10,10,size=1000)\n",
    "\n",
    "W=np.reshape(W,(1000,1))\n",
    "b=np.reshape(b,(1000,1))\n",
    "x=np.reshape(x,(1000,1))\n",
    "\n",
    "mu=np.dot(np.transpose(W),x)+b\n",
    "sigma=0.1*10\n",
    "\n",
    "y=np.random.normal(mu,sigma,size=1000)\n",
    "\n",
    "plt.plot(y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* 1 번차 epoch*******\n",
      "result\n",
      "[[ -8.24755302  42.5748461 ]\n",
      " [  0.53029429   2.19422096]\n",
      " [ -2.13874718  14.25798247]\n",
      " [  4.64061585 -16.09029894]\n",
      " [  4.27514945 -13.21119801]\n",
      " [  8.14812538 -32.24893528]\n",
      " [  8.36420131 -32.94629813]\n",
      " [ -0.31585884   7.68652955]\n",
      " [  5.77857804 -21.62842356]\n",
      " [  0.36894634   4.64983269]]\n",
      "{'W': array([-4.58844226]), 'B': 5.283435420559947}\n",
      "\n",
      " 0 ~ 2 열\n",
      "[[ 8.14812538]\n",
      " [ 8.36420131]\n",
      " [-8.24755302]]\n",
      "[[-32.24893528]\n",
      " [-32.94629813]\n",
      " [ 42.5748461 ]]\n",
      "before\n",
      "{'W': array([-4.58844226]), 'B': 5.283435420559947}\n",
      "after\n",
      "{'W': array([[-4.49613238]]), 'B': array([5.27247028])}\n",
      "\n",
      " 3 ~ 5 열\n",
      "[[-2.13874718]\n",
      " [-0.31585884]\n",
      " [ 0.36894634]]\n",
      "[[14.25798247]\n",
      " [ 7.68652955]\n",
      " [ 4.64983269]]\n",
      "before\n",
      "{'W': array([[-4.49613238]]), 'B': array([5.27247028])}\n",
      "after\n",
      "{'W': array([[-4.46779218]]), 'B': array([5.30046092])}\n",
      "\n",
      " 6 ~ 8 열\n",
      "[[4.27514945]\n",
      " [5.77857804]]\n",
      "[[-13.21119801]\n",
      " [-21.62842356]]\n",
      "before\n",
      "{'W': array([[-4.46779218]]), 'B': array([5.30046092])}\n",
      "after\n",
      "{'W': array([[-4.54589236]]), 'B': array([5.29000935])}\n",
      "Loss 0.6464110246009004\n",
      "=================================\n",
      "******* 2 번차 epoch*******\n",
      "result\n",
      "[[ -8.24755302  42.5748461 ]\n",
      " [ -2.13874718  14.25798247]\n",
      " [  4.64061585 -16.09029894]\n",
      " [  8.14812538 -32.24893528]\n",
      " [  8.36420131 -32.94629813]\n",
      " [  0.36894634   4.64983269]\n",
      " [  5.77857804 -21.62842356]\n",
      " [ -0.31585884   7.68652955]\n",
      " [  4.27514945 -13.21119801]\n",
      " [  0.53029429   2.19422096]]\n",
      "{'W': array([[-4.54589236]]), 'B': array([5.29000935])}\n",
      "\n",
      " 0 ~ 2 열\n",
      "[[ 8.14812538]\n",
      " [ 8.36420131]\n",
      " [-8.24755302]]\n",
      "[[-32.24893528]\n",
      " [-32.94629813]\n",
      " [ 42.5748461 ]]\n",
      "before\n",
      "{'W': array([[-4.54589236]]), 'B': array([5.29000935])}\n",
      "after\n",
      "{'W': array([[-4.62859093]]), 'B': array([5.27161647])}\n",
      "\n",
      " 3 ~ 5 열\n",
      "[[-2.13874718]\n",
      " [-0.31585884]\n",
      " [ 0.36894634]]\n",
      "[[14.25798247]\n",
      " [ 7.68652955]\n",
      " [ 4.64983269]]\n",
      "before\n",
      "{'W': array([[-4.62859093]]), 'B': array([5.27161647])}\n",
      "after\n",
      "{'W': array([[-4.58754349]]), 'B': array([5.29413307])}\n",
      "\n",
      " 6 ~ 8 열\n",
      "[[4.27514945]\n",
      " [5.77857804]]\n",
      "[[-13.21119801]\n",
      " [-21.62842356]]\n",
      "before\n",
      "{'W': array([[-4.58754349]]), 'B': array([5.29413307])}\n",
      "after\n",
      "{'W': array([[-4.54062301]]), 'B': array([5.30801356])}\n",
      "Loss 0.6420612067295816\n",
      "=================================\n",
      "******* 3 번차 epoch*******\n",
      "result\n",
      "[[ -0.31585884   7.68652955]\n",
      " [  0.53029429   2.19422096]\n",
      " [  8.36420131 -32.94629813]\n",
      " [  4.64061585 -16.09029894]\n",
      " [  4.27514945 -13.21119801]\n",
      " [  8.14812538 -32.24893528]\n",
      " [ -8.24755302  42.5748461 ]\n",
      " [ -2.13874718  14.25798247]\n",
      " [  0.36894634   4.64983269]\n",
      " [  5.77857804 -21.62842356]]\n",
      "{'W': array([[-4.54062301]]), 'B': array([5.30801356])}\n",
      "\n",
      " 0 ~ 2 열\n",
      "[[ 8.14812538]\n",
      " [ 8.36420131]\n",
      " [-8.24755302]]\n",
      "[[-32.24893528]\n",
      " [-32.94629813]\n",
      " [ 42.5748461 ]]\n",
      "before\n",
      "{'W': array([[-4.54062301]]), 'B': array([5.30801356])}\n",
      "after\n",
      "{'W': array([[-4.64783595]]), 'B': array([5.28766943])}\n",
      "\n",
      " 3 ~ 5 열\n",
      "[[-2.13874718]\n",
      " [-0.31585884]\n",
      " [ 0.36894634]]\n",
      "[[14.25798247]\n",
      " [ 7.68652955]\n",
      " [ 4.64983269]]\n",
      "before\n",
      "{'W': array([[-4.64783595]]), 'B': array([5.28766943])}\n",
      "after\n",
      "{'W': array([[-4.60426747]]), 'B': array([5.30842008])}\n",
      "\n",
      " 6 ~ 8 열\n",
      "[[4.27514945]\n",
      " [5.77857804]]\n",
      "[[-13.21119801]\n",
      " [-21.62842356]]\n",
      "before\n",
      "{'W': array([[-4.60426747]]), 'B': array([5.30842008])}\n",
      "after\n",
      "{'W': array([[-4.54293757]]), 'B': array([5.32509185])}\n",
      "Loss 0.6382672564262986\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "xlis = []\n",
    "ylis = []\n",
    "flis = [] \n",
    "wlis = []\n",
    "\n",
    "'''\n",
    "plt.scatter(xlis,flis)\n",
    "plt.scatter(xlis,ylis)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "'''\n",
    "#print(result[:,0])\n",
    "\n",
    "def linear_regression(minibatch_size, epoch_size):\n",
    "    R=10\n",
    "    size=1\n",
    "    weights={}\n",
    "    #data_set={}    \n",
    "    loss_grad={}    # dJdW, dJdB 저장공간\n",
    "    forward_info={} # 순방향 저장공간\n",
    "    batch={}\n",
    "    \n",
    "    W= np.random.uniform(-R,R,size=size)\n",
    "    b= np.random.uniform(-R,R,size=size)\n",
    "    b= random.choice(b)\n",
    "\n",
    "    for i in range(10):\n",
    "        x = np.random.uniform(-R,R,size=size)\n",
    "        y = np.random.normal(W*x+b,1,size=size)\n",
    "        xlis.append(x)\n",
    "        ylis.append(y)\n",
    "        flis.append(W*x+b)\n",
    "        \n",
    "    x=np.array(xlis)\n",
    "    y=np.array(ylis)\n",
    "    \n",
    "    weights['W']=W\n",
    "    weights['B']=b\n",
    "\n",
    "    result=np.concatenate((x,y),axis=1)\n",
    "       \n",
    "    train_idx=int(result.shape[0]*0.85)\n",
    "    dev_idx=int(result.shape[0]*0.05)\n",
    "    test_idx=int(result.shape[0]*0.1)\n",
    "    \n",
    "    train_data_set=result[0:train_idx,:]\n",
    "    test_data_set=result[train_idx:train_idx+test_idx,:]\n",
    "    dev_data_set=result[train_idx+test_idx:train_idx+test_idx+dev_idx,:]\n",
    "    \n",
    "    for j in range(1,epoch_size+1):\n",
    "        print('*******',j,'번차 epoch*******')\n",
    "        result=np.random.permutation(result)\n",
    "        \n",
    "        X_batch= train_data_set[:,0]\n",
    "        y_batch= train_data_set[:,1]\n",
    "        X_batch=np.reshape(X_batch,(train_idx,size))\n",
    "        y_batch=np.reshape(y_batch,(train_idx,size))\n",
    "\n",
    "        number_minibatch= np.int(np.ceil(X_batch.shape[0]/minibatch_size))\n",
    "    \n",
    "    #    assert X_batch.shape[0] == y_batch.shape[0]\n",
    "    #    assert X_batch.shape[1] == weights['W'].shape[0]\n",
    "        print('result')\n",
    "        print(result)\n",
    "        \n",
    "        print(weights)\n",
    "        \n",
    "        for i in range(1, number_minibatch+1):\n",
    "            \n",
    "           \n",
    "            print('\\n',minibatch_size*i-(minibatch_size-1)-1,'~',minibatch_size*i-1,'열')\n",
    "            X_batch1=X_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "            y1=y_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "            \n",
    "            print(X_batch1)\n",
    "            print(y1)\n",
    "            \n",
    "            N=weights['W']*X_batch1\n",
    "            f= N+weights['B']\n",
    "            loss=np.mean(np.power(y1-f,2))\n",
    "            \n",
    "            forward_info['X']= X_batch1\n",
    "            forward_info['N']= N       # \n",
    "            forward_info['f']= f       # 예측값\n",
    "            forward_info['y']= y1 # 실제값\n",
    "\n",
    "            # 전체코드로 본 도함수 계산과정\n",
    "            batch_size=forward_info['X'].shape[0]\n",
    "            dJdf=-2*(forward_info['y']-forward_info['f'])\n",
    "            dfdN=np.ones_like(forward_info['N']) \n",
    "            dfdB=np.ones_like(forward_info['N'])\n",
    "            dJdN=dJdf*dfdN \n",
    "            dNdW=np.transpose(forward_info['X'],(1,0))\n",
    "\n",
    "            dJdW=np.dot(dNdW, dJdN)\n",
    "            dLdB=(dJdf*dfdB).sum(axis=0)\n",
    "\n",
    "            loss_grad['W']=dJdW\n",
    "            loss_grad['B']=dLdB\n",
    "            print('before')\n",
    "            print(weights)\n",
    "\n",
    "            for key in weights.keys():\n",
    "                weights[key]=weights[key]- 0.01 * loss_grad[key]\n",
    "\n",
    "            print('after')\n",
    "            print(weights)\n",
    "    \n",
    "        N=weights['W']*X_batch1\n",
    "        f= N+weights['B']\n",
    "        loss=np.mean(np.power(y1-f,2))\n",
    "        print('Loss',loss)\n",
    "        print('=================================')\n",
    "linear_regression(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* 1 번차 epoch *************\n",
      "Loss 5.4445406568145575e+32\n",
      "=================================\n",
      "************* 2 번차 epoch *************\n",
      "Loss 2.2151292849141153e+67\n",
      "=================================\n",
      "************* 3 번차 epoch *************\n",
      "Loss 9.012326398449458e+101\n",
      "=================================\n",
      "************* 4 번차 epoch *************\n",
      "Loss 3.6666946559436707e+136\n",
      "=================================\n",
      "************* 5 번차 epoch *************\n",
      "Loss 1.4918067883381319e+171\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "xlis = []\n",
    "ylis = []\n",
    "flis = [] \n",
    "wlis = []\n",
    "\n",
    "'''\n",
    "plt.scatter(xlis,flis)\n",
    "plt.scatter(xlis,ylis)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "'''\n",
    "#print(result[:,0])\n",
    "\n",
    "def linear_regression(minibatch_size, epoch_size):\n",
    "    R=10\n",
    "    size=1\n",
    "    weights={}\n",
    "    #data_set={}    \n",
    "    loss_grad={}    # dJdW, dJdB 저장공간\n",
    "    forward_info={} # 순방향 저장공간\n",
    "    batch={}\n",
    "    \n",
    "    W= np.random.uniform(-R,R,size=size)\n",
    "    b= np.random.uniform(-R,R,size=size)\n",
    "    b= random.choice(b)\n",
    "\n",
    "    for i in range(1000):\n",
    "        x = np.random.uniform(-R,R,size=size)\n",
    "        y = np.random.normal(W*x+b,1,size=size)\n",
    "        xlis.append(x)\n",
    "        ylis.append(y)\n",
    "        flis.append(W*x+b)\n",
    "        \n",
    "    x=np.array(xlis)\n",
    "    y=np.array(ylis)\n",
    "    \n",
    "    weights['W']=W\n",
    "    weights['B']=b\n",
    "\n",
    "    result=np.concatenate((x,y),axis=1)\n",
    "       \n",
    "    train_idx=int(result.shape[0]*0.85)\n",
    "    dev_idx=int(result.shape[0]*0.05)\n",
    "    test_idx=int(result.shape[0]*0.1)\n",
    "    \n",
    "    train_data_set=result[0:train_idx,:]\n",
    "    test_data_set=result[train_idx:train_idx+test_idx,:]\n",
    "    dev_data_set=result[train_idx+test_idx:train_idx+test_idx+dev_idx,:]\n",
    "\n",
    "    \n",
    "    for j in range(1,epoch_size+1):\n",
    "        print('*************',j,'번차 epoch *************')\n",
    "        result=np.random.permutation(result)\n",
    "   \n",
    "        X_batch= train_data_set[:,0]\n",
    "        y_batch= train_data_set[:,1]\n",
    "        X_batch=np.reshape(X_batch,(train_idx,size))\n",
    "        y_batch=np.reshape(y_batch,(train_idx,size))\n",
    "\n",
    "        number_minibatch= np.int(np.ceil(X_batch.shape[0]/minibatch_size))\n",
    "    \n",
    "    #    assert X_batch.shape[0] == y_batch.shape[0]\n",
    "    #    assert X_batch.shape[1] == weights['W'].shape[0]\n",
    "        \n",
    "        for i in range(1, number_minibatch+1):\n",
    "            #print('\\n',minibatch_size*i-(minibatch_size-1)-1,'~',minibatch_size*i-1,'열')\n",
    "            \n",
    "            \n",
    "            #80~104까지 하나의 함수로 만들면 될거같은데. 그러면 train,test,dev의 mse를 구할 수 있을거 같다.\n",
    "            #함수(데이터,number_minibatch+1)\n",
    "            X_batch1=X_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "            y1=y_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "            \n",
    "            N=weights['W']*X_batch1\n",
    "            f= N+weights['B']\n",
    "            loss=np.mean(np.power(y1-f,2))\n",
    "            \n",
    "            forward_info['X']= X_batch1\n",
    "            forward_info['N']= N       # \n",
    "            forward_info['f']= f       # 예측값\n",
    "            forward_info['y']= y1 # 실제값\n",
    "\n",
    "            # 전체코드로 본 도함수 계산과정\n",
    "            batch_size=forward_info['X'].shape[0]\n",
    "            dJdf=-2*(forward_info['y']-forward_info['f'])\n",
    "            dfdN=np.ones_like(forward_info['N']) \n",
    "            dfdB=np.ones_like(forward_info['N'])\n",
    "            dJdN=dJdf*dfdN \n",
    "            dNdW=np.transpose(forward_info['X'],(1,0))\n",
    "\n",
    "            dJdW=np.dot(dNdW, dJdN)\n",
    "            dLdB=(dJdf*dfdB).sum(axis=0)\n",
    "\n",
    "            loss_grad['W']=dJdW\n",
    "            loss_grad['B']=dLdB\n",
    "\n",
    "            for key in weights.keys():\n",
    "                weights[key]=weights[key]- 0.01 * loss_grad[key]\n",
    "        \n",
    "        N=weights['W']*X_batch1\n",
    "        f= N+weights['B']\n",
    "        loss=np.mean(np.power(y1-f,2))\n",
    "        print('Loss',loss)\n",
    "        print('=================================')\n",
    "linear_regression(90,5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_data\n",
      "************* 1 번차 epoch *************\n",
      "Loss 1.0251186028544\n",
      "************* 2 번차 epoch *************\n",
      "Loss 1.0247450994273\n",
      "************* 3 번차 epoch *************\n",
      "Loss 1.0244845077011\n",
      "************* 4 번차 epoch *************\n",
      "Loss 1.0244003296697\n",
      "************* 5 번차 epoch *************\n",
      "Loss 1.0243966728465\n",
      "************* 6 번차 epoch *************\n",
      "Loss 1.0243611402880\n",
      "************* 7 번차 epoch *************\n",
      "Loss 1.0243444063185\n",
      "************* 8 번차 epoch *************\n",
      "Loss 1.0243400045635\n",
      "************* 9 번차 epoch *************\n",
      "Loss 1.0243306641645\n",
      "************* 10 번차 epoch *************\n",
      "Loss 1.0243219284221\n",
      "************* 11 번차 epoch *************\n",
      "Loss 1.0243315756471\n",
      "************* 12 번차 epoch *************\n",
      "Loss 1.0243084729215\n",
      "************* 13 번차 epoch *************\n",
      "Loss 1.0243047063338\n",
      "************* 14 번차 epoch *************\n",
      "Loss 1.0243016912768\n",
      "************* 15 번차 epoch *************\n",
      "Loss 1.0242998467909\n",
      "************* 16 번차 epoch *************\n",
      "Loss 1.0242901621544\n",
      "************* 17 번차 epoch *************\n",
      "Loss 1.0243099914432\n",
      "************* 18 번차 epoch *************\n",
      "Loss 1.0242778476962\n",
      "************* 19 번차 epoch *************\n",
      "Loss 1.0242829863679\n",
      "************* 20 번차 epoch *************\n",
      "Loss 1.0242618778520\n",
      "************* 21 번차 epoch *************\n",
      "Loss 1.0242605290711\n",
      "************* 22 번차 epoch *************\n",
      "Loss 1.0242496962261\n",
      "************* 23 번차 epoch *************\n",
      "Loss 1.0242446249941\n",
      "************* 24 번차 epoch *************\n",
      "Loss 1.0242504794232\n",
      "************* 25 번차 epoch *************\n",
      "Loss 1.0242353633351\n",
      "************* 26 번차 epoch *************\n",
      "Loss 1.0242601571859\n",
      "************* 27 번차 epoch *************\n",
      "Loss 1.0242310331067\n",
      "************* 28 번차 epoch *************\n",
      "Loss 1.0242663673787\n",
      "************* 29 번차 epoch *************\n",
      "Loss 1.0242396631886\n",
      "************* 30 번차 epoch *************\n",
      "Loss 1.0242148917734\n",
      "\n",
      "Test_data\n",
      "************* 1 번차 epoch *************\n",
      "Loss 1.0239466734750\n",
      "************* 2 번차 epoch *************\n",
      "Loss 1.0219205339948\n",
      "************* 3 번차 epoch *************\n",
      "Loss 1.0202239078118\n",
      "************* 4 번차 epoch *************\n",
      "Loss 1.0186804016514\n",
      "************* 5 번차 epoch *************\n",
      "Loss 1.0173580787066\n",
      "************* 6 번차 epoch *************\n",
      "Loss 1.0162581583592\n",
      "************* 7 번차 epoch *************\n",
      "Loss 1.0152639036278\n",
      "************* 8 번차 epoch *************\n",
      "Loss 1.0143720779555\n",
      "************* 9 번차 epoch *************\n",
      "Loss 1.0135734757872\n",
      "************* 10 번차 epoch *************\n",
      "Loss 1.0129108899223\n",
      "************* 11 번차 epoch *************\n",
      "Loss 1.0123031609090\n",
      "************* 12 번차 epoch *************\n",
      "Loss 1.0117531734970\n",
      "************* 13 번차 epoch *************\n",
      "Loss 1.0112474098561\n",
      "************* 14 번차 epoch *************\n",
      "Loss 1.0108167708661\n",
      "************* 15 번차 epoch *************\n",
      "Loss 1.0104523384199\n",
      "************* 16 번차 epoch *************\n",
      "Loss 1.0101077568201\n",
      "************* 17 번차 epoch *************\n",
      "Loss 1.0097895223495\n",
      "************* 18 번차 epoch *************\n",
      "Loss 1.0095100893589\n",
      "************* 19 번차 epoch *************\n",
      "Loss 1.0092551838811\n",
      "************* 20 번차 epoch *************\n",
      "Loss 1.0090470449941\n",
      "************* 21 번차 epoch *************\n",
      "Loss 1.0088571984698\n",
      "************* 22 번차 epoch *************\n",
      "Loss 1.0086669814855\n",
      "************* 23 번차 epoch *************\n",
      "Loss 1.0084877404111\n",
      "************* 24 번차 epoch *************\n",
      "Loss 1.0083346756088\n",
      "************* 25 번차 epoch *************\n",
      "Loss 1.0081895704277\n",
      "************* 26 번차 epoch *************\n",
      "Loss 1.0080588850416\n",
      "************* 27 번차 epoch *************\n",
      "Loss 1.0079321814638\n",
      "************* 28 번차 epoch *************\n",
      "Loss 1.0078109311742\n",
      "************* 29 번차 epoch *************\n",
      "Loss 1.0076932613569\n",
      "************* 30 번차 epoch *************\n",
      "Loss 1.0075877397530\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#유력\n",
    "np.set_printoptions(precision=7)\n",
    "xlis = []\n",
    "ylis = []\n",
    "flis = [] \n",
    "wlis = []\n",
    "\n",
    "R=10\n",
    "size=1\n",
    "weights={}\n",
    "#data_set={}    \n",
    "loss_grad={}    # dJdW, dJdB 저장공간\n",
    "forward_info={} # 순방향 저장공간\n",
    "batch={}\n",
    "\n",
    "W= np.random.uniform(-R,R,size=size)\n",
    "b= np.random.uniform(-R,R,size=size)\n",
    "b= random.choice(b)\n",
    "\n",
    "for i in range(1000):\n",
    "    x = np.random.uniform(-R,R,size=size)\n",
    "    y = np.random.normal(W*x+b,1,size=size)\n",
    "    xlis.append(x)\n",
    "    ylis.append(y)\n",
    "    flis.append(W*x+b)\n",
    "\n",
    "x=np.array(xlis)\n",
    "y=np.array(ylis)\n",
    "\n",
    "weights['W']=W\n",
    "weights['B']=b\n",
    "\n",
    "result=np.concatenate((x,y),axis=1)\n",
    "\n",
    "train_idx=int(result.shape[0]*0.85)\n",
    "dev_idx=int(result.shape[0]*0.05)\n",
    "test_idx=int(result.shape[0]*0.1)\n",
    "\n",
    "train_data_set=result[0:train_idx,:]\n",
    "test_data_set=result[train_idx:train_idx+test_idx,:]\n",
    "dev_data_set=result[train_idx+test_idx:train_idx+test_idx+dev_idx,:]\n",
    "\n",
    "def linear_regression(data, idx, minibatch_size, epoch_size):\n",
    "    data_list=[]\n",
    "    X_batch= data[:,0]\n",
    "    y_batch= data[:,1]\n",
    "    X_batch=np.reshape(X_batch,(idx,size))\n",
    "    y_batch=np.reshape(y_batch,(idx,size))\n",
    "\n",
    "    number_minibatch= np.int(np.ceil(X_batch.shape[0]/minibatch_size))\n",
    "    \n",
    "    \n",
    "    for j in range(1,epoch_size+1):\n",
    "        print('*************',j,'번차 epoch *************')\n",
    "        data=np.random.permutation(data)\n",
    "        X_batch= data[:,0]\n",
    "        y_batch= data[:,1]\n",
    "        X_batch=np.reshape(X_batch,(idx,size))\n",
    "        y_batch=np.reshape(y_batch,(idx,size))\n",
    "        \n",
    "        number_minibatch= np.int(np.ceil(X_batch.shape[0]/minibatch_size))\n",
    "    \n",
    "    #    assert X_batch.shape[0] == y_batch.shape[0]\n",
    "    #    assert X_batch.shape[1] == weights['W'].shape[0]\n",
    "        \n",
    "        for i in range(1, number_minibatch+1):\n",
    "            X_batch_temp=X_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "            y_temp=y_batch[minibatch_size*i-(minibatch_size-1)-1:minibatch_size*i]\n",
    "            \n",
    "            N=weights['W']*X_batch_temp\n",
    "            f= N+weights['B']\n",
    "            loss=np.mean(np.power(y_temp-f,2))\n",
    "            \n",
    "            forward_info['X']= X_batch_temp\n",
    "            forward_info['N']= N       # \n",
    "            forward_info['f']= f       # 예측값\n",
    "            forward_info['y']= y_temp # 실제값\n",
    "\n",
    "            # 전체코드로 본 도함수 계산과정\n",
    "            batch_size=forward_info['X'].shape[0]\n",
    "            dJdf=-2*(forward_info['y']-forward_info['f'])\n",
    "            dfdN=np.ones_like(forward_info['N']) \n",
    "            dfdB=np.ones_like(forward_info['N'])\n",
    "            dJdN=dJdf*dfdN \n",
    "            dNdW=np.transpose(forward_info['X'],(1,0))\n",
    "\n",
    "            dJdW=np.dot(dNdW, dJdN)\n",
    "            dLdB=(dJdf*dfdB).sum(axis=0)\n",
    "\n",
    "            loss_grad['W']=dJdW\n",
    "            loss_grad['B']=dLdB\n",
    "\n",
    "            for key in weights.keys():\n",
    "                weights[key]=weights[key]- 0.00001 * loss_grad[key]\n",
    "        \n",
    "        N=weights['W']*X_batch\n",
    "        f= N+weights['B']\n",
    "        loss=np.mean(np.power(y_batch-f,2))\n",
    "        print('Loss',loss)\n",
    "      \n",
    "        #print('=================================')\n",
    "        \n",
    "        data_list.append(loss)\n",
    "        \n",
    "    X_batch = list(X_batch)\n",
    "    \n",
    "    #epoch에 따른 loss 출력도 가능\n",
    "    return plt.scatter(X_batch_temp, y_temp, label = 'name')\n",
    "\n",
    "print('Train_data')\n",
    "train_ = linear_regression(train_data_set,train_idx,50,30)\n",
    "\n",
    "#print('\\ndev_data')\n",
    "#dev_ = linear_regression(dev_data_set,dev_idx,20,30)\n",
    "\n",
    "print('\\nTest_data')\n",
    "Test_ = linear_regression(test_data_set,test_idx,50,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a6e0a891e07d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-------------'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'번째 backpropagation-------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mdJd_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdJda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'length' is not defined"
     ]
    }
   ],
   "source": [
    "for x in range(length):\n",
    "    print('-------------',l[x],'번째 backpropagation-------------')\n",
    "    for y in range(x):\n",
    "        if (y == 0):\n",
    "            dJd_ = dJda\n",
    "        else :\n",
    "            '''print('dJd_')\n",
    "            print(dJd_)\n",
    "            \n",
    "            print('affine')\n",
    "            print(affine[y-1])\n",
    "            \n",
    "            dJd_ = Relu.backward(affine[y-1])\n",
    "            \n",
    "            print('dJd_NEXT')\n",
    "            print(dJd_)\n",
    "            \n",
    "            dJd_ = np.dot(np.transpose(param_w[y-1]),dJd_)'''\n",
    "            \n",
    "            print('np.transpose(param_w)')\n",
    "            print(np.transpose(param_w[y-1]))\n",
    "            dJd_ = np.dot(np.transpose(param_w[y-1]),dJd_)\n",
    "            print('dJd_')\n",
    "            print(dJd_)\n",
    "            dJd_ = Relu.backward(affine[y-1])\n",
    "            print('dJd_')\n",
    "            print(dJd_)\n",
    "            \n",
    "    dJdw = np.dot(dJd_,np.transpose(affine[y]))\n",
    "    dJdb = dJd_,*np.ones_like(affine[y])\n",
    "        \n",
    "        \n",
    "    grad_w.append(dJdw)\n",
    "    grad_b.append(dJdb)\n",
    "    #grad_affine.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
