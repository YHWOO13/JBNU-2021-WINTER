{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "driver = webdriver.Chrome('C:/Users/LG/Downloads/chromedriver_win32/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = \"https://brunch.co.kr/keyword/\"\n",
    "url_keyword= [\"지구한바퀴_세계여행\",\n",
    "      #\"감성_에세이\",\n",
    "      #\"사랑·이별\",\n",
    "      #\"인문학·철학\",\n",
    "      #\"문화·예술\",\n",
    "      #\"그림·웹툰\",\n",
    "      #\"오늘은_이런_책\",\n",
    "     ]\n",
    "url_end = \"?q=g\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  1.92it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "writer_cutter = re.compile('@@\\w*')\n",
    "scroll_num = 5\n",
    "subscriber_limit = 30\n",
    "post_limit = 10\n",
    "post_lists = []\n",
    "crawled = []\n",
    "\n",
    "for keyword in url_keyword:\n",
    "    driver.get(url_base + keyword + url_end)\n",
    "    time.sleep(1)\n",
    "    driver.get(url_base + keyword + url_end)\n",
    "    time.sleep(1)\n",
    "    for _ in tqdm(range(scroll_num)):    \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-300);\")\n",
    "        time.sleep(0.5)\n",
    "    time.sleep(3)\n",
    "    html_source = driver.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    for item in soup.find_all(\"a\",{\"class\":\"link_post\"}):\n",
    "        tmp = writer_cutter.match(item.get(\"href\")[1:])\n",
    "        if not tmp == None:\n",
    "            crawled.append(tmp.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  1.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  1.93it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2,505'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-50c09c614045>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0msubscriber_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubscriber_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0msubscriber_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubscriber_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpost_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"articleTab link_tab\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"txt_tab\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2,505'"
     ]
    }
   ],
   "source": [
    "for writer_id in crawled:\n",
    "    driver.get(\"https://brunch.co.kr/\" + writer_id + \"#articles\")\n",
    "    html_source = driver.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "\n",
    "    subscriber_count = soup.find(\"a\",{\"class\":\"link_count #follower\"}).find(\"span\", {\"class\":\"num_count\"}).string\n",
    "    if subscriber_count[-1] == \"만\":\n",
    "        subscriber_count = float(subscriber_count[:-1]) * 10000\n",
    "    else:\n",
    "        subscriber_count = float(subscriber_count)\n",
    "\n",
    "    post_count = int(soup.find(\"a\", {\"class\":\"articleTab link_tab\"}).find(\"span\", {\"class\":\"txt_tab\"}).string[2:])\n",
    "    if post_count >= post_limit and subscriber_count >= subscriber_limit:\n",
    "        for _ in tqdm(range(scroll_num)):    \n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-300);\")\n",
    "            time.sleep(0.5)\n",
    "        time.sleep(3)\n",
    "        html_source = driver.page_source\n",
    "        soup = BeautifulSoup(html_source, 'html.parser')\n",
    "        for item in soup.find_all(\"a\",{\"class\":\"link_post\"}):\n",
    "            post_lists.append(item.get(\"href\")[1:])\n",
    "print(post_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "['@@6qq0', '@@ejI', '@@1f0N', '@@ejI', '@@ejI', '@@9JzN', '@@bOkk', '@@dgOe', '@@bzNa', '@@7TX4', '@@ddf6', '@@1xRj', '@@c0MI', '@@1Mxf', '@@aOCX', '@@dbZC', '@@aiNt', '@@3fbw', '@@aSCk', '@@aA7C', '@@9Edj', '@@2eRo', '@@23TU', '@@wlQ', '@@czpj', '@@50uw', '@@aiNt', '@@ddf6', '@@23TU', '@@cJBi', '@@d1Xx', '@@cvVi', '@@3fuW', '@@1Kt0', '@@5hT6', '@@3fuW', '@@cgRg', '@@cVx8', '@@B7y', '@@McL', '@@8z7c', '@@9JzN', '@@dc8V', '@@aA7C', '@@bqul', '@@8bJs', '@@6ftO', '@@cnXy', '@@dgOe', '@@cmux', '@@uRQ', '@@bOkk', '@@JxX', '@@dfjA']\n",
      "44\n",
      "['@@aA7C', '@@2eRo', '@@cVx8', '@@dgOe', '@@bzNa', '@@9JzN', '@@3fuW', '@@8z7c', '@@McL', '@@6qq0', '@@cmux', '@@5hT6', '@@cnXy', '@@aSCk', '@@B7y', '@@50uw', '@@d1Xx', '@@1xRj', '@@1Kt0', '@@wlQ', '@@1f0N', '@@dc8V', '@@9Edj', '@@cJBi', '@@3fbw', '@@23TU', '@@bOkk', '@@cvVi', '@@czpj', '@@aOCX', '@@6ftO', '@@7TX4', '@@1Mxf', '@@8bJs', '@@dbZC', '@@ddf6', '@@JxX', '@@uRQ', '@@c0MI', '@@bqul', '@@dfjA', '@@ejI', '@@aiNt', '@@cgRg']\n"
     ]
    }
   ],
   "source": [
    "print(len(crawled))\n",
    "print(crawled)\n",
    "crawled = list(set(crawled))\n",
    "print(len(crawled))\n",
    "print(crawled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ids in crawled:\n",
    "    writer_url = base_url + writer_id + \"#articles\"\n",
    "    driver.get(writer_url)\n",
    "    html_source = driver.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    soup.find(\"a\",{\"class\":\"link_count #follower\"}).find(\"span\", {\"class=\"\"num_count\"}).span.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_source = driver.page_source\n",
    "soup = BeautifulSoup(html_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled = soup.find_all(\"a\",{\"clas\":\"link_post\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://brunch.co.kr/\"\n",
    "post_links = [BASE_URL+i[\"href\"][1:] for i in crawled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"지구한바퀴.json\", \"w\") as f:\n",
    "    json.dump(post_links,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./지구한바퀴.json\", \"rb\") as f:\n",
    "    post_link = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/Users/LG/Downloads/chromedriver_win32/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 success\n",
      "1 success\n",
      "2 success\n",
      "3 success\n",
      "4 success\n",
      "5 success\n",
      "6 success\n",
      "7 success\n",
      "8 success\n",
      "9 success\n",
      "10 success\n",
      "11 success\n",
      "12 success\n",
      "13 success\n",
      "14 success\n",
      "15 success\n",
      "16 success\n",
      "17 success\n",
      "18 success\n",
      "19 success\n",
      "20 success\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-cc79e9095a29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# politeness policy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mhtml_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, link in enumerate(post_link):\n",
    "    i = idx\n",
    "    driver.get(link)\n",
    "    time.sleep(1) # politeness policy\n",
    "    html_source = driver.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    try:\n",
    "#         print(\"first\")\n",
    "        temp = soup.find('div',{'class':\"wrap_body text_align_left finish_txt\"})\n",
    "        text = temp.text\n",
    "        if text==\"\":\n",
    "            print(\"empty text\")\n",
    "        else:\n",
    "            with open(f\"./지구한바퀴/book_{i}.txt\", \"w\", -1, 'utf-8') as f:\n",
    "                f.write(text)\n",
    "                print(str(i)+\" success\")\n",
    "    except:\n",
    "        try:\n",
    "#             print(\"second\")\n",
    "            text = ''\n",
    "            for tmp in soup.find_all('p',{'class':\"wrap_item item_type_text\"}):\n",
    "                text += tmp.text\n",
    "            if text==\"\":\n",
    "                for tmp in soup.find_all('h4',{'class':\"wrap_item item_type_text\"}):\n",
    "                    text += tmp.text\n",
    "            with open(f\"./지구한바퀴/book_{i}.txt\", \"w\", -1, 'utf-8') as f:\n",
    "                f.write(text)\n",
    "                print(str(i)+\" success\")\n",
    "        except:\n",
    "            try:\n",
    "#                 print(\"third\")\n",
    "                soup = BeautifulSoup(html_source, 'html.parser')\n",
    "                text = ''\n",
    "                for tmp in soup.find_all('h4',{'class':\"wrap_item item_type_text\"}):\n",
    "                    text += tmp.text\n",
    "                text = text.replace(\"\\xa0\", \"\")\n",
    "                with open(f\"./지구한바퀴/book_{i}.txt\", \"w\", -1, 'utf-8') as f:\n",
    "                    f.write(text)\n",
    "                    print(str(i)+\" success\")\n",
    "            except: \n",
    "                print(str(i)+\" error\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = soup.find('div',{'class':\"wrap_body text_align_left finish_txt\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./지구한바퀴/book_{idx}.txt\", \"w\", -1, 'utf-8') as f:\n",
    "                f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
